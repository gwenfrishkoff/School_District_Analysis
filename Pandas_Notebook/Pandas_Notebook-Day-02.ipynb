{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4 Day 02\n",
    "# Instructor Turn - 01- Cleaning Data - üë©‚Äçüè´üßë‚Äçüè´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Name of the CSV file\n",
    "file = 'Resources/donors2008.csv'\n",
    "\n",
    "# The correct encoding must be used to read the CSV in pandas\n",
    "df = pd.read_csv(file, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LastName</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>Employer</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Amount</th>\n",
       "      <th>FIELD8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron</td>\n",
       "      <td>Eugene</td>\n",
       "      <td>State Department</td>\n",
       "      <td>Dulles</td>\n",
       "      <td>VA</td>\n",
       "      <td>20189</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abadi</td>\n",
       "      <td>Barbara</td>\n",
       "      <td>Abadi &amp; Co.</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10021</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adamany</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Rockford</td>\n",
       "      <td>IL</td>\n",
       "      <td>61103</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adams</td>\n",
       "      <td>Lorraine</td>\n",
       "      <td>Self</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10026</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adams</td>\n",
       "      <td>Marion</td>\n",
       "      <td>None</td>\n",
       "      <td>Exeter</td>\n",
       "      <td>NH</td>\n",
       "      <td>03833</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LastName FirstName          Employer      City State    Zip  Amount  FIELD8\n",
       "0    Aaron    Eugene  State Department    Dulles    VA  20189   500.0     NaN\n",
       "1    Abadi   Barbara       Abadi & Co.  New York    NY  10021   200.0     NaN\n",
       "2  Adamany   Anthony           Retired  Rockford    IL  61103   500.0     NaN\n",
       "3    Adams  Lorraine              Self  New York    NY  10026   200.0     NaN\n",
       "4    Adams    Marion              None    Exeter    NH  03833   100.0     NaN"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview of the DataFrame\n",
    "# Note that FIELD8 is likely a meaningless column\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LastName</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>Employer</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron</td>\n",
       "      <td>Eugene</td>\n",
       "      <td>State Department</td>\n",
       "      <td>Dulles</td>\n",
       "      <td>VA</td>\n",
       "      <td>20189</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abadi</td>\n",
       "      <td>Barbara</td>\n",
       "      <td>Abadi &amp; Co.</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10021</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adamany</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Rockford</td>\n",
       "      <td>IL</td>\n",
       "      <td>61103</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adams</td>\n",
       "      <td>Lorraine</td>\n",
       "      <td>Self</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10026</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adams</td>\n",
       "      <td>Marion</td>\n",
       "      <td>None</td>\n",
       "      <td>Exeter</td>\n",
       "      <td>NH</td>\n",
       "      <td>03833</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LastName FirstName          Employer      City State    Zip  Amount\n",
       "0    Aaron    Eugene  State Department    Dulles    VA  20189   500.0\n",
       "1    Abadi   Barbara       Abadi & Co.  New York    NY  10021   200.0\n",
       "2  Adamany   Anthony           Retired  Rockford    IL  61103   500.0\n",
       "3    Adams  Lorraine              Self  New York    NY  10026   200.0\n",
       "4    Adams    Marion              None    Exeter    NH  03833   100.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete extraneous column\n",
    "del df['FIELD8']\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LastName     1776\n",
       "FirstName    1776\n",
       "Employer     1743\n",
       "City         1776\n",
       "State        1776\n",
       "Zip          1776\n",
       "Amount       1776\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify incomplete rows\n",
    "df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with missing information\n",
    "df = df.dropna(how='any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LastName     1743\n",
       "FirstName    1743\n",
       "Employer     1743\n",
       "City         1743\n",
       "State        1743\n",
       "Zip          1743\n",
       "Amount       1743\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify dropped rows\n",
    "df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LastName      object\n",
       "FirstName     object\n",
       "Employer      object\n",
       "City          object\n",
       "State         object\n",
       "Zip           object\n",
       "Amount       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Amount column is the wrong data type. It should be numeric.\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pd.to_numeric() method to convert the datatype of the Amount column\n",
    "df['Amount'] = pd.to_numeric(df['Amount'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that the Amount column datatype has been made numeric\n",
    "df['Amount'].dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None                             249\n",
       "Self                             241\n",
       "Retired                          126\n",
       "Self Employed                     39\n",
       "Self-Employed                     34\n",
       "                                ... \n",
       "Fox                                1\n",
       "Puma Springs Vineyards             1\n",
       "South Brooklyn Legal Services      1\n",
       "Greene & Seaver, PC                1\n",
       "JDS Uniphase                       1\n",
       "Name: Employer, Length: 1011, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display an overview of the Employers column\n",
    "df['Employer'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up Employer category. Replace 'Self Employed' and 'Self' with 'Self-Employed'\n",
    "df['Employer'] = df['Employer'].replace(\n",
    "    {'Self Employed': 'Self-Employed', 'Self': 'Self-Employed'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Self-Employed                    314\n",
       "None                             249\n",
       "Retired                          126\n",
       "Google                             6\n",
       "Not Employed                       4\n",
       "                                ... \n",
       "Fox                                1\n",
       "Puma Springs Vineyards             1\n",
       "South Brooklyn Legal Services      1\n",
       "Greene & Seaver, PC                1\n",
       "JDS Uniphase                       1\n",
       "Name: Employer, Length: 1009, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify clean-up.\n",
    "df['Employer'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Self-Employed                    314\n",
       "None                             249\n",
       "Retired                          126\n",
       "Unemployed                         8\n",
       "Google                             6\n",
       "                                ... \n",
       "Fox                                1\n",
       "Puma Springs Vineyards             1\n",
       "South Brooklyn Legal Services      1\n",
       "Greene & Seaver, PC                1\n",
       "JDS Uniphase                       1\n",
       "Name: Employer, Length: 1008, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Employer'] = df['Employer'].replace({'Not Employed': 'Unemployed'})\n",
    "df['Employer'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1743.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>640.124750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1242.343265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Amount\n",
       "count  1743.000000\n",
       "mean    640.124750\n",
       "std    1242.343265\n",
       "min       5.000000\n",
       "25%     200.000000\n",
       "50%     250.000000\n",
       "75%     500.000000\n",
       "max    5000.000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a statistical overview\n",
    "# We can infer the maximum allowable individual contribution from 'max'\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Students Turn - 02 - Training Grounds - üë©‚Äçüéìüë®‚Äçüéì\n",
    "## Portland Crime\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Read in the csv using Pandas and print out the DataFrame that is returned.\n",
    "\n",
    "* Get a count of rows within the DataFrame in order to determine if there are any null values.\n",
    "\n",
    "* Drop the rows which contain null values.\n",
    "\n",
    "* Search through the \"Offense Type\" column and \"replace\" any similar values with one consistent value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Crime Against</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Number of Records</th>\n",
       "      <th>Occur Date</th>\n",
       "      <th>Occur Month Year</th>\n",
       "      <th>Occur Time</th>\n",
       "      <th>Offense Category</th>\n",
       "      <th>Offense Count</th>\n",
       "      <th>Offense Type</th>\n",
       "      <th>Open Data Lat</th>\n",
       "      <th>Open Data Lon</th>\n",
       "      <th>Open Data X</th>\n",
       "      <th>Open Data Y</th>\n",
       "      <th>Report Date</th>\n",
       "      <th>Report Month Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17-X4762181</td>\n",
       "      <td>Person</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/96</td>\n",
       "      <td>1/1/96</td>\n",
       "      <td>800</td>\n",
       "      <td>Sex Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Rape</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/26/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17-X4757824</td>\n",
       "      <td>Property</td>\n",
       "      <td>Centennial</td>\n",
       "      <td>1</td>\n",
       "      <td>1/20/00</td>\n",
       "      <td>1/1/00</td>\n",
       "      <td>1615</td>\n",
       "      <td>Fraud Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Identity Theft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/20/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200 BLOCK OF SE 78TH AVE</td>\n",
       "      <td>17-900367</td>\n",
       "      <td>Property</td>\n",
       "      <td>Montavilla</td>\n",
       "      <td>1</td>\n",
       "      <td>12/1/03</td>\n",
       "      <td>12/1/03</td>\n",
       "      <td>800</td>\n",
       "      <td>Fraud Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>False Pretenses/Swindle/Confidence Game</td>\n",
       "      <td>45.5207</td>\n",
       "      <td>-122.583</td>\n",
       "      <td>7668150.0</td>\n",
       "      <td>682825.0</td>\n",
       "      <td>1/9/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17-X4748982</td>\n",
       "      <td>Property</td>\n",
       "      <td>Southwest Hills</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/10</td>\n",
       "      <td>1/1/10</td>\n",
       "      <td>0</td>\n",
       "      <td>Fraud Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Identity Theft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/5/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17-X4748982</td>\n",
       "      <td>Property</td>\n",
       "      <td>Southwest Hills</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/10</td>\n",
       "      <td>1/1/10</td>\n",
       "      <td>0</td>\n",
       "      <td>Larceny Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>All Other Larceny</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/5/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41027</th>\n",
       "      <td>8800 BLOCK OF NE SANDY BLVD</td>\n",
       "      <td>17-285386</td>\n",
       "      <td>Society</td>\n",
       "      <td>Sumner</td>\n",
       "      <td>1</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "      <td>535</td>\n",
       "      <td>Drug/Narcotic Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Drug/Narcotic Violations</td>\n",
       "      <td>45.5554</td>\n",
       "      <td>-122.571</td>\n",
       "      <td>7671560.0</td>\n",
       "      <td>695399.0</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41028</th>\n",
       "      <td>9700 BLOCK OF SE STARK ST</td>\n",
       "      <td>17-286082</td>\n",
       "      <td>Society</td>\n",
       "      <td>Hazelwood</td>\n",
       "      <td>1</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "      <td>1619</td>\n",
       "      <td>Prostitution Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Prostitution</td>\n",
       "      <td>45.5191</td>\n",
       "      <td>-122.563</td>\n",
       "      <td>7673292.0</td>\n",
       "      <td>682101.0</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41029</th>\n",
       "      <td>9700 BLOCK OF SE STARK ST</td>\n",
       "      <td>17-286413</td>\n",
       "      <td>Society</td>\n",
       "      <td>Hazelwood</td>\n",
       "      <td>1</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "      <td>1959</td>\n",
       "      <td>Prostitution Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Prostitution</td>\n",
       "      <td>45.5191</td>\n",
       "      <td>-122.563</td>\n",
       "      <td>7673292.0</td>\n",
       "      <td>682101.0</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41030</th>\n",
       "      <td>UNKNOWN ADDRESS</td>\n",
       "      <td>17-286445</td>\n",
       "      <td>Society</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "      <td>2021</td>\n",
       "      <td>Prostitution Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Prostitution</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41031</th>\n",
       "      <td>8000 BLOCK OF SE POWELL BLVD</td>\n",
       "      <td>17-286659</td>\n",
       "      <td>Society</td>\n",
       "      <td>Foster-Powell</td>\n",
       "      <td>1</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "      <td>2354</td>\n",
       "      <td>Weapon Law Violations</td>\n",
       "      <td>1</td>\n",
       "      <td>Weapons Law Violations</td>\n",
       "      <td>45.4974</td>\n",
       "      <td>-122.580</td>\n",
       "      <td>7668725.0</td>\n",
       "      <td>674298.0</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41032 rows √ó 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Address  Case Number Crime Against  \\\n",
       "0                               NaN  17-X4762181        Person   \n",
       "1                               NaN  17-X4757824      Property   \n",
       "2          200 BLOCK OF SE 78TH AVE    17-900367      Property   \n",
       "3                               NaN  17-X4748982      Property   \n",
       "4                               NaN  17-X4748982      Property   \n",
       "...                             ...          ...           ...   \n",
       "41027   8800 BLOCK OF NE SANDY BLVD    17-285386       Society   \n",
       "41028     9700 BLOCK OF SE STARK ST    17-286082       Society   \n",
       "41029     9700 BLOCK OF SE STARK ST    17-286413       Society   \n",
       "41030               UNKNOWN ADDRESS    17-286445       Society   \n",
       "41031  8000 BLOCK OF SE POWELL BLVD    17-286659       Society   \n",
       "\n",
       "          Neighborhood  Number of Records Occur Date Occur Month Year  \\\n",
       "0                  NaN                  1     1/1/96           1/1/96   \n",
       "1           Centennial                  1    1/20/00           1/1/00   \n",
       "2           Montavilla                  1    12/1/03          12/1/03   \n",
       "3      Southwest Hills                  1     1/1/10           1/1/10   \n",
       "4      Southwest Hills                  1     1/1/10           1/1/10   \n",
       "...                ...                ...        ...              ...   \n",
       "41027           Sumner                  1    8/31/17           8/1/17   \n",
       "41028        Hazelwood                  1    8/31/17           8/1/17   \n",
       "41029        Hazelwood                  1    8/31/17           8/1/17   \n",
       "41030              NaN                  1    8/31/17           8/1/17   \n",
       "41031    Foster-Powell                  1    8/31/17           8/1/17   \n",
       "\n",
       "       Occur Time        Offense Category  Offense Count  \\\n",
       "0             800            Sex Offenses              1   \n",
       "1            1615          Fraud Offenses              1   \n",
       "2             800          Fraud Offenses              1   \n",
       "3               0          Fraud Offenses              1   \n",
       "4               0        Larceny Offenses              1   \n",
       "...           ...                     ...            ...   \n",
       "41027         535  Drug/Narcotic Offenses              1   \n",
       "41028        1619   Prostitution Offenses              1   \n",
       "41029        1959   Prostitution Offenses              1   \n",
       "41030        2021   Prostitution Offenses              1   \n",
       "41031        2354   Weapon Law Violations              1   \n",
       "\n",
       "                                  Offense Type  Open Data Lat  Open Data Lon  \\\n",
       "0                                         Rape            NaN            NaN   \n",
       "1                               Identity Theft            NaN            NaN   \n",
       "2      False Pretenses/Swindle/Confidence Game        45.5207       -122.583   \n",
       "3                               Identity Theft            NaN            NaN   \n",
       "4                            All Other Larceny            NaN            NaN   \n",
       "...                                        ...            ...            ...   \n",
       "41027                 Drug/Narcotic Violations        45.5554       -122.571   \n",
       "41028                             Prostitution        45.5191       -122.563   \n",
       "41029                             Prostitution        45.5191       -122.563   \n",
       "41030                             Prostitution            NaN            NaN   \n",
       "41031                   Weapons Law Violations        45.4974       -122.580   \n",
       "\n",
       "       Open Data X  Open Data Y Report Date Report Month Year  \n",
       "0              NaN          NaN     1/26/17            1/1/17  \n",
       "1              NaN          NaN     1/20/17            1/1/17  \n",
       "2        7668150.0     682825.0      1/9/17            1/1/17  \n",
       "3              NaN          NaN      1/5/17            1/1/17  \n",
       "4              NaN          NaN      1/5/17            1/1/17  \n",
       "...            ...          ...         ...               ...  \n",
       "41027    7671560.0     695399.0     8/31/17            8/1/17  \n",
       "41028    7673292.0     682101.0     8/31/17            8/1/17  \n",
       "41029    7673292.0     682101.0     8/31/17            8/1/17  \n",
       "41030          NaN          NaN     8/31/17            8/1/17  \n",
       "41031    7668725.0     674298.0     8/31/17            8/1/17  \n",
       "\n",
       "[41032 rows x 17 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# Reference the file where the CSV is located\n",
    "crime_csv_path = \"Resources/crime_incident_data2017.csv\"\n",
    "\n",
    "# Import the data into a Pandas DataFrame\n",
    "crime_df = pd.read_csv(crime_csv_path)\n",
    "crime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address              37365\n",
       "Case Number          41032\n",
       "Crime Against        41032\n",
       "Neighborhood         39712\n",
       "Number of Records    41032\n",
       "Occur Date           41032\n",
       "Occur Month Year     41032\n",
       "Occur Time           41032\n",
       "Offense Category     41032\n",
       "Offense Count        41032\n",
       "Offense Type         41032\n",
       "Open Data Lat        36712\n",
       "Open Data Lon        36712\n",
       "Open Data X          36712\n",
       "Open Data Y          36712\n",
       "Report Date          41032\n",
       "Report Month Year    41032\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for missing values\n",
    "crime_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null rows\n",
    "no_null_crime_df = crime_df.dropna(how='any') #NOTE: (how:) arg is opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address              36146\n",
       "Case Number          36146\n",
       "Crime Against        36146\n",
       "Neighborhood         36146\n",
       "Number of Records    36146\n",
       "Occur Date           36146\n",
       "Occur Month Year     36146\n",
       "Occur Time           36146\n",
       "Offense Category     36146\n",
       "Offense Count        36146\n",
       "Offense Type         36146\n",
       "Open Data Lat        36146\n",
       "Open Data Lon        36146\n",
       "Open Data X          36146\n",
       "Open Data Y          36146\n",
       "Report Date          36146\n",
       "Report Month Year    36146\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify counts\n",
    "no_null_crime_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11907779294209397"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4886/41032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Theft From Motor Vehicle                       6947\n",
       "Motor Vehicle Theft                            4689\n",
       "All Other Larceny                              4558\n",
       "Vandalism                                      3863\n",
       "Burglary                                       2824\n",
       "Shoplifting                                    2259\n",
       "Identity Theft                                 1794\n",
       "Simple Assault                                 1216\n",
       "Drug/Narcotic Violations                       1095\n",
       "Theft of Motor Vehicle Parts or Accessories    1073\n",
       "Intimidation                                    900\n",
       "Theft From Building                             895\n",
       "False Pretenses/Swindle/Confidence Game         870\n",
       "Aggravated Assault                              839\n",
       "Robbery                                         608\n",
       "Counterfeiting/Forgery                          448\n",
       "Weapons Law Violations                          266\n",
       "Credit Card/ATM Fraud                           226\n",
       "Arson                                           200\n",
       "Prostitution                                    145\n",
       "Pocket-Picking                                   94\n",
       "Purse-Snatching                                  89\n",
       "Embezzlement                                     73\n",
       "Stolen Property Offenses                         57\n",
       "Kidnapping/Abduction                             22\n",
       "Theft From Coin-Operated Machine or Device       20\n",
       "Hacking/Computer Invasion                        19\n",
       "Animal Cruelty                                   17\n",
       "Pornography/Obscene Material                     10\n",
       "Extortion/Blackmail                               8\n",
       "Assisting or Promoting Prostitution               7\n",
       "Drug Equipment Violations                         6\n",
       "Impersonation                                     4\n",
       "Wire Fraud                                        3\n",
       "Commercial Sex Acts                               1\n",
       "Welfare Fraud                                     1\n",
       "Name: Offense Type, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if there are any values with mispelled or similar values in \"Offense Type\"\n",
    "no_null_crime_df[\"Offense Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Crime Against</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Number of Records</th>\n",
       "      <th>Occur Date</th>\n",
       "      <th>Occur Month Year</th>\n",
       "      <th>Occur Time</th>\n",
       "      <th>Offense Category</th>\n",
       "      <th>Offense Count</th>\n",
       "      <th>Offense Type</th>\n",
       "      <th>Open Data Lat</th>\n",
       "      <th>Open Data Lon</th>\n",
       "      <th>Open Data X</th>\n",
       "      <th>Open Data Y</th>\n",
       "      <th>Report Date</th>\n",
       "      <th>Report Month Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200 BLOCK OF SE 78TH AVE</td>\n",
       "      <td>17-900367</td>\n",
       "      <td>Property</td>\n",
       "      <td>Montavilla</td>\n",
       "      <td>1</td>\n",
       "      <td>12/1/03</td>\n",
       "      <td>12/1/03</td>\n",
       "      <td>800</td>\n",
       "      <td>Fraud Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>False Pretenses/Swindle/Confidence Game</td>\n",
       "      <td>45.5207</td>\n",
       "      <td>-122.583</td>\n",
       "      <td>7668150.0</td>\n",
       "      <td>682825.0</td>\n",
       "      <td>1/9/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5400 BLOCK OF NE MALLORY AVE</td>\n",
       "      <td>17-900129</td>\n",
       "      <td>Property</td>\n",
       "      <td>King</td>\n",
       "      <td>1</td>\n",
       "      <td>11/28/10</td>\n",
       "      <td>11/1/10</td>\n",
       "      <td>1612</td>\n",
       "      <td>Fraud Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Identity Theft</td>\n",
       "      <td>45.5625</td>\n",
       "      <td>-122.664</td>\n",
       "      <td>7647987.0</td>\n",
       "      <td>698581.0</td>\n",
       "      <td>1/3/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5000 BLOCK OF NE 19TH AVE</td>\n",
       "      <td>17-901079</td>\n",
       "      <td>Property</td>\n",
       "      <td>Vernon</td>\n",
       "      <td>1</td>\n",
       "      <td>11/8/13</td>\n",
       "      <td>11/1/13</td>\n",
       "      <td>1200</td>\n",
       "      <td>Fraud Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>False Pretenses/Swindle/Confidence Game</td>\n",
       "      <td>45.5594</td>\n",
       "      <td>-122.646</td>\n",
       "      <td>7652567.0</td>\n",
       "      <td>697337.0</td>\n",
       "      <td>1/26/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5000 BLOCK OF NE 19TH AVE</td>\n",
       "      <td>17-901079</td>\n",
       "      <td>Property</td>\n",
       "      <td>Vernon</td>\n",
       "      <td>1</td>\n",
       "      <td>11/8/13</td>\n",
       "      <td>11/1/13</td>\n",
       "      <td>1200</td>\n",
       "      <td>Fraud Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Identity Theft</td>\n",
       "      <td>45.5594</td>\n",
       "      <td>-122.646</td>\n",
       "      <td>7652567.0</td>\n",
       "      <td>697337.0</td>\n",
       "      <td>1/26/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12000 BLOCK OF SE PINE ST</td>\n",
       "      <td>17-900253</td>\n",
       "      <td>Property</td>\n",
       "      <td>Hazelwood</td>\n",
       "      <td>1</td>\n",
       "      <td>1/6/14</td>\n",
       "      <td>1/1/14</td>\n",
       "      <td>805</td>\n",
       "      <td>Fraud Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Credit Card/ATM Fraud</td>\n",
       "      <td>45.5204</td>\n",
       "      <td>-122.539</td>\n",
       "      <td>7679522.0</td>\n",
       "      <td>682404.0</td>\n",
       "      <td>1/6/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41026</th>\n",
       "      <td>10200 BLOCK OF NE SANDY BLVD</td>\n",
       "      <td>17-286419</td>\n",
       "      <td>Society</td>\n",
       "      <td>Parkrose</td>\n",
       "      <td>1</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "      <td>2005</td>\n",
       "      <td>Drug/Narcotic Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Drug/Narcotic Violations</td>\n",
       "      <td>45.5591</td>\n",
       "      <td>-122.557</td>\n",
       "      <td>7675224.0</td>\n",
       "      <td>696649.0</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41027</th>\n",
       "      <td>8800 BLOCK OF NE SANDY BLVD</td>\n",
       "      <td>17-285386</td>\n",
       "      <td>Society</td>\n",
       "      <td>Sumner</td>\n",
       "      <td>1</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "      <td>535</td>\n",
       "      <td>Drug/Narcotic Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Drug/Narcotic Violations</td>\n",
       "      <td>45.5554</td>\n",
       "      <td>-122.571</td>\n",
       "      <td>7671560.0</td>\n",
       "      <td>695399.0</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41028</th>\n",
       "      <td>9700 BLOCK OF SE STARK ST</td>\n",
       "      <td>17-286082</td>\n",
       "      <td>Society</td>\n",
       "      <td>Hazelwood</td>\n",
       "      <td>1</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "      <td>1619</td>\n",
       "      <td>Prostitution Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Prostitution</td>\n",
       "      <td>45.5191</td>\n",
       "      <td>-122.563</td>\n",
       "      <td>7673292.0</td>\n",
       "      <td>682101.0</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41029</th>\n",
       "      <td>9700 BLOCK OF SE STARK ST</td>\n",
       "      <td>17-286413</td>\n",
       "      <td>Society</td>\n",
       "      <td>Hazelwood</td>\n",
       "      <td>1</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "      <td>1959</td>\n",
       "      <td>Prostitution Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Prostitution</td>\n",
       "      <td>45.5191</td>\n",
       "      <td>-122.563</td>\n",
       "      <td>7673292.0</td>\n",
       "      <td>682101.0</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41031</th>\n",
       "      <td>8000 BLOCK OF SE POWELL BLVD</td>\n",
       "      <td>17-286659</td>\n",
       "      <td>Society</td>\n",
       "      <td>Foster-Powell</td>\n",
       "      <td>1</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "      <td>2354</td>\n",
       "      <td>Weapon Law Violations</td>\n",
       "      <td>1</td>\n",
       "      <td>Weapons Law Violations</td>\n",
       "      <td>45.4974</td>\n",
       "      <td>-122.580</td>\n",
       "      <td>7668725.0</td>\n",
       "      <td>674298.0</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36146 rows √ó 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Address Case Number Crime Against   Neighborhood  \\\n",
       "2          200 BLOCK OF SE 78TH AVE   17-900367      Property     Montavilla   \n",
       "5      5400 BLOCK OF NE MALLORY AVE   17-900129      Property           King   \n",
       "6         5000 BLOCK OF NE 19TH AVE   17-901079      Property         Vernon   \n",
       "7         5000 BLOCK OF NE 19TH AVE   17-901079      Property         Vernon   \n",
       "8         12000 BLOCK OF SE PINE ST   17-900253      Property      Hazelwood   \n",
       "...                             ...         ...           ...            ...   \n",
       "41026  10200 BLOCK OF NE SANDY BLVD   17-286419       Society       Parkrose   \n",
       "41027   8800 BLOCK OF NE SANDY BLVD   17-285386       Society         Sumner   \n",
       "41028     9700 BLOCK OF SE STARK ST   17-286082       Society      Hazelwood   \n",
       "41029     9700 BLOCK OF SE STARK ST   17-286413       Society      Hazelwood   \n",
       "41031  8000 BLOCK OF SE POWELL BLVD   17-286659       Society  Foster-Powell   \n",
       "\n",
       "       Number of Records Occur Date Occur Month Year  Occur Time  \\\n",
       "2                      1    12/1/03          12/1/03         800   \n",
       "5                      1   11/28/10          11/1/10        1612   \n",
       "6                      1    11/8/13          11/1/13        1200   \n",
       "7                      1    11/8/13          11/1/13        1200   \n",
       "8                      1     1/6/14           1/1/14         805   \n",
       "...                  ...        ...              ...         ...   \n",
       "41026                  1    8/31/17           8/1/17        2005   \n",
       "41027                  1    8/31/17           8/1/17         535   \n",
       "41028                  1    8/31/17           8/1/17        1619   \n",
       "41029                  1    8/31/17           8/1/17        1959   \n",
       "41031                  1    8/31/17           8/1/17        2354   \n",
       "\n",
       "             Offense Category  Offense Count  \\\n",
       "2              Fraud Offenses              1   \n",
       "5              Fraud Offenses              1   \n",
       "6              Fraud Offenses              1   \n",
       "7              Fraud Offenses              1   \n",
       "8              Fraud Offenses              1   \n",
       "...                       ...            ...   \n",
       "41026  Drug/Narcotic Offenses              1   \n",
       "41027  Drug/Narcotic Offenses              1   \n",
       "41028   Prostitution Offenses              1   \n",
       "41029   Prostitution Offenses              1   \n",
       "41031   Weapon Law Violations              1   \n",
       "\n",
       "                                  Offense Type  Open Data Lat  Open Data Lon  \\\n",
       "2      False Pretenses/Swindle/Confidence Game        45.5207       -122.583   \n",
       "5                               Identity Theft        45.5625       -122.664   \n",
       "6      False Pretenses/Swindle/Confidence Game        45.5594       -122.646   \n",
       "7                               Identity Theft        45.5594       -122.646   \n",
       "8                        Credit Card/ATM Fraud        45.5204       -122.539   \n",
       "...                                        ...            ...            ...   \n",
       "41026                 Drug/Narcotic Violations        45.5591       -122.557   \n",
       "41027                 Drug/Narcotic Violations        45.5554       -122.571   \n",
       "41028                             Prostitution        45.5191       -122.563   \n",
       "41029                             Prostitution        45.5191       -122.563   \n",
       "41031                   Weapons Law Violations        45.4974       -122.580   \n",
       "\n",
       "       Open Data X  Open Data Y Report Date Report Month Year  \n",
       "2        7668150.0     682825.0      1/9/17            1/1/17  \n",
       "5        7647987.0     698581.0      1/3/17            1/1/17  \n",
       "6        7652567.0     697337.0     1/26/17            1/1/17  \n",
       "7        7652567.0     697337.0     1/26/17            1/1/17  \n",
       "8        7679522.0     682404.0      1/6/17            1/1/17  \n",
       "...            ...          ...         ...               ...  \n",
       "41026    7675224.0     696649.0     8/31/17            8/1/17  \n",
       "41027    7671560.0     695399.0     8/31/17            8/1/17  \n",
       "41028    7673292.0     682101.0     8/31/17            8/1/17  \n",
       "41029    7673292.0     682101.0     8/31/17            8/1/17  \n",
       "41031    7668725.0     674298.0     8/31/17            8/1/17  \n",
       "\n",
       "[36146 rows x 17 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining similar offenses together\n",
    "no_null_crime_df = no_null_crime_df.replace(\n",
    "    {\"Commercial Sex Acts\": \"Prostitution\", \"Assisting or Promoting Prostitution\": \"Prostitution\",\"Pocket-Picking\": \"Purse-Snatching\"})\n",
    "no_null_crime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Theft From Motor Vehicle                       6947\n",
       "Motor Vehicle Theft                            4689\n",
       "All Other Larceny                              4558\n",
       "Vandalism                                      3863\n",
       "Burglary                                       2824\n",
       "Shoplifting                                    2259\n",
       "Identity Theft                                 1794\n",
       "Simple Assault                                 1216\n",
       "Drug/Narcotic Violations                       1095\n",
       "Theft of Motor Vehicle Parts or Accessories    1073\n",
       "Intimidation                                    900\n",
       "Theft From Building                             895\n",
       "False Pretenses/Swindle/Confidence Game         870\n",
       "Aggravated Assault                              839\n",
       "Robbery                                         608\n",
       "Counterfeiting/Forgery                          448\n",
       "Weapons Law Violations                          266\n",
       "Credit Card/ATM Fraud                           226\n",
       "Arson                                           200\n",
       "Purse-Snatching                                 183\n",
       "Prostitution                                    153\n",
       "Embezzlement                                     73\n",
       "Stolen Property Offenses                         57\n",
       "Kidnapping/Abduction                             22\n",
       "Theft From Coin-Operated Machine or Device       20\n",
       "Hacking/Computer Invasion                        19\n",
       "Animal Cruelty                                   17\n",
       "Pornography/Obscene Material                     10\n",
       "Extortion/Blackmail                               8\n",
       "Drug Equipment Violations                         6\n",
       "Impersonation                                     4\n",
       "Wire Fraud                                        3\n",
       "Welfare Fraud                                     1\n",
       "Name: Offense Type, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if you comnbined similar offenses correctly in \"Offense Type\".\n",
    "no_null_crime_df[\"Offense Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200 BLOCK OF LLOYD CENTER            165\n",
       "1100 BLOCK OF NE 102ND AVE            158\n",
       "10100 BLOCK OF SE WASHINGTON ST       117\n",
       "1500 BLOCK OF N TOMAHAWK ISLAND DR    106\n",
       "1100 BLOCK OF N HAYDEN MEADOWS DR     103\n",
       "                                     ... \n",
       "I205 FWY SB AT / SE FOSTER RD           1\n",
       "5700 BLOCK OF NE 17TH AVE               1\n",
       "1100 BLOCK OF SE 13TH AVE               1\n",
       "8200 BLOCK OF N MARINE DR               1\n",
       "2100 BLOCK OF NW THURMAN ST             1\n",
       "Name: Address, Length: 14658, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of crimes against property, society, and person.\n",
    "no_null_crime_df[\"Address\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Crime Against</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Number of Records</th>\n",
       "      <th>Occur Date</th>\n",
       "      <th>Occur Month Year</th>\n",
       "      <th>Occur Time</th>\n",
       "      <th>Offense Category</th>\n",
       "      <th>Offense Count</th>\n",
       "      <th>Offense Type</th>\n",
       "      <th>Open Data Lat</th>\n",
       "      <th>Open Data Lon</th>\n",
       "      <th>Open Data X</th>\n",
       "      <th>Open Data Y</th>\n",
       "      <th>Report Date</th>\n",
       "      <th>Report Month Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5000 BLOCK OF NE 19TH AVE</td>\n",
       "      <td>17-901079</td>\n",
       "      <td>Property</td>\n",
       "      <td>Vernon</td>\n",
       "      <td>1</td>\n",
       "      <td>11/8/13</td>\n",
       "      <td>11/1/13</td>\n",
       "      <td>1200</td>\n",
       "      <td>Fraud Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>False Pretenses/Swindle/Confidence Game</td>\n",
       "      <td>45.5594</td>\n",
       "      <td>-122.646</td>\n",
       "      <td>7652567.0</td>\n",
       "      <td>697337.0</td>\n",
       "      <td>1/26/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5000 BLOCK OF NE 19TH AVE</td>\n",
       "      <td>17-901079</td>\n",
       "      <td>Property</td>\n",
       "      <td>Vernon</td>\n",
       "      <td>1</td>\n",
       "      <td>11/8/13</td>\n",
       "      <td>11/1/13</td>\n",
       "      <td>1200</td>\n",
       "      <td>Fraud Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Identity Theft</td>\n",
       "      <td>45.5594</td>\n",
       "      <td>-122.646</td>\n",
       "      <td>7652567.0</td>\n",
       "      <td>697337.0</td>\n",
       "      <td>1/26/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1000 BLOCK OF NE EMERSON ST</td>\n",
       "      <td>17-901190</td>\n",
       "      <td>Property</td>\n",
       "      <td>Vernon</td>\n",
       "      <td>1</td>\n",
       "      <td>11/26/16</td>\n",
       "      <td>11/1/16</td>\n",
       "      <td>2040</td>\n",
       "      <td>Fraud Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Identity Theft</td>\n",
       "      <td>45.5619</td>\n",
       "      <td>-122.655</td>\n",
       "      <td>7650320.0</td>\n",
       "      <td>698297.0</td>\n",
       "      <td>1/29/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1000 BLOCK OF NE EMERSON ST</td>\n",
       "      <td>17-901190</td>\n",
       "      <td>Property</td>\n",
       "      <td>Vernon</td>\n",
       "      <td>1</td>\n",
       "      <td>11/26/16</td>\n",
       "      <td>11/1/16</td>\n",
       "      <td>2040</td>\n",
       "      <td>Larceny Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>All Other Larceny</td>\n",
       "      <td>45.5619</td>\n",
       "      <td>-122.655</td>\n",
       "      <td>7650320.0</td>\n",
       "      <td>698297.0</td>\n",
       "      <td>1/29/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>5300 BLOCK OF NE 14TH PL</td>\n",
       "      <td>17-2593</td>\n",
       "      <td>Property</td>\n",
       "      <td>Vernon</td>\n",
       "      <td>1</td>\n",
       "      <td>12/19/16</td>\n",
       "      <td>12/1/16</td>\n",
       "      <td>900</td>\n",
       "      <td>Larceny Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>All Other Larceny</td>\n",
       "      <td>45.5618</td>\n",
       "      <td>-122.651</td>\n",
       "      <td>7651314.0</td>\n",
       "      <td>698264.0</td>\n",
       "      <td>1/3/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39229</th>\n",
       "      <td>2000 BLOCK OF NE ALBERTA ST</td>\n",
       "      <td>17-272724</td>\n",
       "      <td>Property</td>\n",
       "      <td>Vernon</td>\n",
       "      <td>1</td>\n",
       "      <td>8/21/17</td>\n",
       "      <td>8/1/17</td>\n",
       "      <td>633</td>\n",
       "      <td>Burglary</td>\n",
       "      <td>1</td>\n",
       "      <td>Burglary</td>\n",
       "      <td>45.5591</td>\n",
       "      <td>-122.644</td>\n",
       "      <td>7652922.0</td>\n",
       "      <td>697229.0</td>\n",
       "      <td>8/21/17</td>\n",
       "      <td>8/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39294</th>\n",
       "      <td>2000 BLOCK OF NE ALBERTA ST</td>\n",
       "      <td>17-272724</td>\n",
       "      <td>Property</td>\n",
       "      <td>Vernon</td>\n",
       "      <td>1</td>\n",
       "      <td>8/21/17</td>\n",
       "      <td>8/1/17</td>\n",
       "      <td>633</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>1</td>\n",
       "      <td>Vandalism</td>\n",
       "      <td>45.5591</td>\n",
       "      <td>-122.644</td>\n",
       "      <td>7652922.0</td>\n",
       "      <td>697229.0</td>\n",
       "      <td>8/21/17</td>\n",
       "      <td>8/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39759</th>\n",
       "      <td>NE 21ST AVE / NE ALBERTA ST</td>\n",
       "      <td>17-276989</td>\n",
       "      <td>Property</td>\n",
       "      <td>Vernon</td>\n",
       "      <td>1</td>\n",
       "      <td>8/24/17</td>\n",
       "      <td>8/1/17</td>\n",
       "      <td>1500</td>\n",
       "      <td>Larceny Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Purse-Snatching</td>\n",
       "      <td>45.5591</td>\n",
       "      <td>-122.644</td>\n",
       "      <td>7653047.0</td>\n",
       "      <td>697209.0</td>\n",
       "      <td>8/24/17</td>\n",
       "      <td>8/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39875</th>\n",
       "      <td>4800 BLOCK OF NE 14TH PL</td>\n",
       "      <td>17-912435</td>\n",
       "      <td>Property</td>\n",
       "      <td>Vernon</td>\n",
       "      <td>1</td>\n",
       "      <td>8/24/17</td>\n",
       "      <td>8/1/17</td>\n",
       "      <td>0</td>\n",
       "      <td>Larceny Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Theft From Motor Vehicle</td>\n",
       "      <td>45.5581</td>\n",
       "      <td>-122.651</td>\n",
       "      <td>7651302.0</td>\n",
       "      <td>696885.0</td>\n",
       "      <td>8/25/17</td>\n",
       "      <td>8/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40920</th>\n",
       "      <td>1800 BLOCK OF NE JARRETT ST</td>\n",
       "      <td>17-285898</td>\n",
       "      <td>Property</td>\n",
       "      <td>Vernon</td>\n",
       "      <td>1</td>\n",
       "      <td>8/30/17</td>\n",
       "      <td>8/1/17</td>\n",
       "      <td>2130</td>\n",
       "      <td>Motor Vehicle Theft</td>\n",
       "      <td>1</td>\n",
       "      <td>Motor Vehicle Theft</td>\n",
       "      <td>45.5646</td>\n",
       "      <td>-122.647</td>\n",
       "      <td>7652420.0</td>\n",
       "      <td>699227.0</td>\n",
       "      <td>8/31/17</td>\n",
       "      <td>8/1/17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows √ó 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Address Case Number Crime Against Neighborhood  \\\n",
       "6        5000 BLOCK OF NE 19TH AVE   17-901079      Property       Vernon   \n",
       "7        5000 BLOCK OF NE 19TH AVE   17-901079      Property       Vernon   \n",
       "147    1000 BLOCK OF NE EMERSON ST   17-901190      Property       Vernon   \n",
       "148    1000 BLOCK OF NE EMERSON ST   17-901190      Property       Vernon   \n",
       "271       5300 BLOCK OF NE 14TH PL     17-2593      Property       Vernon   \n",
       "...                            ...         ...           ...          ...   \n",
       "39229  2000 BLOCK OF NE ALBERTA ST   17-272724      Property       Vernon   \n",
       "39294  2000 BLOCK OF NE ALBERTA ST   17-272724      Property       Vernon   \n",
       "39759  NE 21ST AVE / NE ALBERTA ST   17-276989      Property       Vernon   \n",
       "39875     4800 BLOCK OF NE 14TH PL   17-912435      Property       Vernon   \n",
       "40920  1800 BLOCK OF NE JARRETT ST   17-285898      Property       Vernon   \n",
       "\n",
       "       Number of Records Occur Date Occur Month Year  Occur Time  \\\n",
       "6                      1    11/8/13          11/1/13        1200   \n",
       "7                      1    11/8/13          11/1/13        1200   \n",
       "147                    1   11/26/16          11/1/16        2040   \n",
       "148                    1   11/26/16          11/1/16        2040   \n",
       "271                    1   12/19/16          12/1/16         900   \n",
       "...                  ...        ...              ...         ...   \n",
       "39229                  1    8/21/17           8/1/17         633   \n",
       "39294                  1    8/21/17           8/1/17         633   \n",
       "39759                  1    8/24/17           8/1/17        1500   \n",
       "39875                  1    8/24/17           8/1/17           0   \n",
       "40920                  1    8/30/17           8/1/17        2130   \n",
       "\n",
       "          Offense Category  Offense Count  \\\n",
       "6           Fraud Offenses              1   \n",
       "7           Fraud Offenses              1   \n",
       "147         Fraud Offenses              1   \n",
       "148       Larceny Offenses              1   \n",
       "271       Larceny Offenses              1   \n",
       "...                    ...            ...   \n",
       "39229             Burglary              1   \n",
       "39294            Vandalism              1   \n",
       "39759     Larceny Offenses              1   \n",
       "39875     Larceny Offenses              1   \n",
       "40920  Motor Vehicle Theft              1   \n",
       "\n",
       "                                  Offense Type  Open Data Lat  Open Data Lon  \\\n",
       "6      False Pretenses/Swindle/Confidence Game        45.5594       -122.646   \n",
       "7                               Identity Theft        45.5594       -122.646   \n",
       "147                             Identity Theft        45.5619       -122.655   \n",
       "148                          All Other Larceny        45.5619       -122.655   \n",
       "271                          All Other Larceny        45.5618       -122.651   \n",
       "...                                        ...            ...            ...   \n",
       "39229                                 Burglary        45.5591       -122.644   \n",
       "39294                                Vandalism        45.5591       -122.644   \n",
       "39759                          Purse-Snatching        45.5591       -122.644   \n",
       "39875                 Theft From Motor Vehicle        45.5581       -122.651   \n",
       "40920                      Motor Vehicle Theft        45.5646       -122.647   \n",
       "\n",
       "       Open Data X  Open Data Y Report Date Report Month Year  \n",
       "6        7652567.0     697337.0     1/26/17            1/1/17  \n",
       "7        7652567.0     697337.0     1/26/17            1/1/17  \n",
       "147      7650320.0     698297.0     1/29/17            1/1/17  \n",
       "148      7650320.0     698297.0     1/29/17            1/1/17  \n",
       "271      7651314.0     698264.0      1/3/17            1/1/17  \n",
       "...            ...          ...         ...               ...  \n",
       "39229    7652922.0     697229.0     8/21/17            8/1/17  \n",
       "39294    7652922.0     697229.0     8/21/17            8/1/17  \n",
       "39759    7653047.0     697209.0     8/24/17            8/1/17  \n",
       "39875    7651302.0     696885.0     8/25/17            8/1/17  \n",
       "40920    7652420.0     699227.0     8/31/17            8/1/17  \n",
       "\n",
       "[97 rows x 17 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new DataFrame that looks into a specific neighborhood\n",
    "vernon_crime_df = no_null_crime_df.loc[no_null_crime_df[\"Neighborhood\"] == \"Vernon\"]\n",
    "vernon_crime_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><strong>Activity 02 Solution ‚úÖ</strong></summary>\n",
    "    \n",
    "```python\n",
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# Reference the file where the CSV is located\n",
    "crime_csv_path = \"Resources/crime_incident_data2017.csv\"\n",
    "\n",
    "# Import the data into a Pandas DataFrame\n",
    "crime_df = pd.read_csv(crime_csv_path)\n",
    "crime_df\n",
    "\n",
    "# look for missing values\n",
    "crime_df.count()\n",
    "\n",
    "# drop null rows\n",
    "no_null_crime_df = crime_df.dropna(how='any')\n",
    "\n",
    "# verify counts\n",
    "no_null_crime_df.count()\n",
    "\n",
    "# Check to see if there are any values with mispelled or similar values in \"Offense Type\"\n",
    "no_null_crime_df[\"Offense Type\"].value_counts()\n",
    "\n",
    "# Combining similar offenses together\n",
    "no_null_crime_df = no_null_crime_df.replace(\n",
    "    {\"Commercial Sex Acts\": \"Prostitution\", \"Assisting or Promoting Prostitution\": \"Prostitution\"})\n",
    "no_null_crime_df\n",
    "\n",
    "# Check to see if you comnbined similar offenses correctly in \"Offense Type\".\n",
    "no_null_crime_df[\"Offense Type\"].value_counts()\n",
    "\n",
    "# Get the number of crimes against property, society, and person.\n",
    "no_null_crime_df[\"Crime Against\"].value_counts()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor Turn - 03 - Loc And Iloc - üë©‚Äçüè´üßë‚Äçüè´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Time zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Peter</td>\n",
       "      <td>Richardson</td>\n",
       "      <td>7-(789)867-9023</td>\n",
       "      <td>Europe/Moscow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Janice</td>\n",
       "      <td>Berry</td>\n",
       "      <td>86-(614)973-1727</td>\n",
       "      <td>Asia/Harbin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Andrea</td>\n",
       "      <td>Hudson</td>\n",
       "      <td>86-(918)527-6371</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Arthur</td>\n",
       "      <td>Mcdonald</td>\n",
       "      <td>420-(553)779-7783</td>\n",
       "      <td>Europe/Prague</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Kathy</td>\n",
       "      <td>Morales</td>\n",
       "      <td>351-(720)541-2124</td>\n",
       "      <td>Europe/Lisbon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id first_name   last_name       Phone Number      Time zone\n",
       "0   1      Peter  Richardson    7-(789)867-9023  Europe/Moscow\n",
       "1   2     Janice       Berry   86-(614)973-1727    Asia/Harbin\n",
       "2   3     Andrea      Hudson   86-(918)527-6371  Asia/Shanghai\n",
       "3   4     Arthur    Mcdonald  420-(553)779-7783  Europe/Prague\n",
       "4   5      Kathy     Morales  351-(720)541-2124  Europe/Lisbon"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = \"Resources/sampleData.csv\"\n",
    "\n",
    "original_df = pd.read_csv(file)\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Time zone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Richardson</th>\n",
       "      <td>1</td>\n",
       "      <td>Peter</td>\n",
       "      <td>7-(789)867-9023</td>\n",
       "      <td>Europe/Moscow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Berry</th>\n",
       "      <td>2</td>\n",
       "      <td>Janice</td>\n",
       "      <td>86-(614)973-1727</td>\n",
       "      <td>Asia/Harbin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hudson</th>\n",
       "      <td>3</td>\n",
       "      <td>Andrea</td>\n",
       "      <td>86-(918)527-6371</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mcdonald</th>\n",
       "      <td>4</td>\n",
       "      <td>Arthur</td>\n",
       "      <td>420-(553)779-7783</td>\n",
       "      <td>Europe/Prague</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morales</th>\n",
       "      <td>5</td>\n",
       "      <td>Kathy</td>\n",
       "      <td>351-(720)541-2124</td>\n",
       "      <td>Europe/Lisbon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id first_name       Phone Number      Time zone\n",
       "last_name                                                  \n",
       "Richardson   1      Peter    7-(789)867-9023  Europe/Moscow\n",
       "Berry        2     Janice   86-(614)973-1727    Asia/Harbin\n",
       "Hudson       3     Andrea   86-(918)527-6371  Asia/Shanghai\n",
       "Mcdonald     4     Arthur  420-(553)779-7783  Europe/Prague\n",
       "Morales      5      Kathy  351-(720)541-2124  Europe/Lisbon"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set new index to last_name\n",
    "df = original_df.set_index(\"last_name\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Loc: 86-(614)973-1727\n"
     ]
    }
   ],
   "source": [
    "# Grab the data contained within the \"Berry\" row and the \"Phone Number\" column\n",
    "berry_phone = df.loc[\"Berry\", \"Phone Number\"]\n",
    "print(\"Using Loc: \" + berry_phone)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Iloc: 86-(614)973-1727\n"
     ]
    }
   ],
   "source": [
    "also_berry_phone = df.iloc[1, 2]\n",
    "print(\"Using Iloc: \" + also_berry_phone)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>Phone Number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Richardson</th>\n",
       "      <td>1</td>\n",
       "      <td>Peter</td>\n",
       "      <td>7-(789)867-9023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Richardson</th>\n",
       "      <td>25</td>\n",
       "      <td>Donald</td>\n",
       "      <td>62-(259)282-5871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Berry</th>\n",
       "      <td>2</td>\n",
       "      <td>Janice</td>\n",
       "      <td>86-(614)973-1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hudson</th>\n",
       "      <td>3</td>\n",
       "      <td>Andrea</td>\n",
       "      <td>86-(918)527-6371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hudson</th>\n",
       "      <td>8</td>\n",
       "      <td>Frances</td>\n",
       "      <td>57-(752)864-4744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hudson</th>\n",
       "      <td>90</td>\n",
       "      <td>Norma</td>\n",
       "      <td>351-(551)598-1822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mcdonald</th>\n",
       "      <td>4</td>\n",
       "      <td>Arthur</td>\n",
       "      <td>420-(553)779-7783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morales</th>\n",
       "      <td>5</td>\n",
       "      <td>Kathy</td>\n",
       "      <td>351-(720)541-2124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id first_name       Phone Number\n",
       "last_name                                   \n",
       "Richardson   1      Peter    7-(789)867-9023\n",
       "Richardson  25     Donald   62-(259)282-5871\n",
       "Berry        2     Janice   86-(614)973-1727\n",
       "Hudson       3     Andrea   86-(918)527-6371\n",
       "Hudson       8    Frances   57-(752)864-4744\n",
       "Hudson      90      Norma  351-(551)598-1822\n",
       "Mcdonald     4     Arthur  420-(553)779-7783\n",
       "Morales      5      Kathy  351-(720)541-2124"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the first five rows of data and the columns from \"id\" to \"Phone Number\"\n",
    "# The problem with using \"last_name\" as the index is that the values are not unique so duplicates are returned\n",
    "# If there are duplicates and loc[] is being used, Pandas will return an error\n",
    "richardson_to_morales = df.loc[[\"Richardson\", \"Berry\", \"Hudson\",\n",
    "                                \"Mcdonald\", \"Morales\"], [\"id\", \"first_name\", \"Phone Number\"]]\n",
    "richardson_to_morales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>Phone Number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Richardson</th>\n",
       "      <td>1</td>\n",
       "      <td>Peter</td>\n",
       "      <td>7-(789)867-9023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Berry</th>\n",
       "      <td>2</td>\n",
       "      <td>Janice</td>\n",
       "      <td>86-(614)973-1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hudson</th>\n",
       "      <td>3</td>\n",
       "      <td>Andrea</td>\n",
       "      <td>86-(918)527-6371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mcdonald</th>\n",
       "      <td>4</td>\n",
       "      <td>Arthur</td>\n",
       "      <td>420-(553)779-7783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id first_name       Phone Number\n",
       "last_name                                   \n",
       "Richardson   1      Peter    7-(789)867-9023\n",
       "Berry        2     Janice   86-(614)973-1727\n",
       "Hudson       3     Andrea   86-(918)527-6371\n",
       "Mcdonald     4     Arthur  420-(553)779-7783"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using iloc[] will not find duplicates since a numeric index is always unique\n",
    "also_richardson_to_morales = df.iloc[0:4, 0:3]\n",
    "also_richardson_to_morales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>Phone Number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Richardson</th>\n",
       "      <td>Peter</td>\n",
       "      <td>7-(789)867-9023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Berry</th>\n",
       "      <td>Janice</td>\n",
       "      <td>86-(614)973-1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hudson</th>\n",
       "      <td>Andrea</td>\n",
       "      <td>86-(918)527-6371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mcdonald</th>\n",
       "      <td>Arthur</td>\n",
       "      <td>420-(553)779-7783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morales</th>\n",
       "      <td>Kathy</td>\n",
       "      <td>351-(720)541-2124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           first_name       Phone Number\n",
       "last_name                               \n",
       "Richardson      Peter    7-(789)867-9023\n",
       "Berry          Janice   86-(614)973-1727\n",
       "Hudson         Andrea   86-(918)527-6371\n",
       "Mcdonald       Arthur  420-(553)779-7783\n",
       "Morales         Kathy  351-(720)541-2124"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following will select all rows for columns `first_name` and `Phone Number`\n",
    "df.loc[:, [\"first_name\", \"Phone Number\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_name\n",
       "Richardson    False\n",
       "Berry         False\n",
       "Hudson        False\n",
       "Mcdonald      False\n",
       "Morales       False\n",
       "Name: first_name, dtype: bool"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the following logic test/conditional statement returns a series of boolean values\n",
    "named_billy = df[\"first_name\"] == \"Billy\"\n",
    "named_billy.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Time zone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Clark</th>\n",
       "      <td>20</td>\n",
       "      <td>Billy</td>\n",
       "      <td>62-(213)345-2549</td>\n",
       "      <td>Asia/Makassar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andrews</th>\n",
       "      <td>23</td>\n",
       "      <td>Billy</td>\n",
       "      <td>86-(859)746-5367</td>\n",
       "      <td>Asia/Chongqing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>59</td>\n",
       "      <td>Billy</td>\n",
       "      <td>86-(878)547-7739</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id first_name      Phone Number       Time zone\n",
       "last_name                                                 \n",
       "Clark      20      Billy  62-(213)345-2549   Asia/Makassar\n",
       "Andrews    23      Billy  86-(859)746-5367  Asia/Chongqing\n",
       "Price      59      Billy  86-(878)547-7739   Asia/Shanghai"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loc and Iloc also allow for conditional statments to filter rows of data\n",
    "# using Loc on the logic test above only returns rows where the result is True\n",
    "only_billys = df.loc[df[\"first_name\"] == \"Billy\", :]\n",
    "only_billys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Time zone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Richardson</th>\n",
       "      <td>1</td>\n",
       "      <td>Peter</td>\n",
       "      <td>7-(789)867-9023</td>\n",
       "      <td>Europe/Moscow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clark</th>\n",
       "      <td>20</td>\n",
       "      <td>Billy</td>\n",
       "      <td>62-(213)345-2549</td>\n",
       "      <td>Asia/Makassar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andrews</th>\n",
       "      <td>23</td>\n",
       "      <td>Billy</td>\n",
       "      <td>86-(859)746-5367</td>\n",
       "      <td>Asia/Chongqing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>59</td>\n",
       "      <td>Billy</td>\n",
       "      <td>86-(878)547-7739</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id first_name      Phone Number       Time zone\n",
       "last_name                                                  \n",
       "Richardson   1      Peter   7-(789)867-9023   Europe/Moscow\n",
       "Clark       20      Billy  62-(213)345-2549   Asia/Makassar\n",
       "Andrews     23      Billy  86-(859)746-5367  Asia/Chongqing\n",
       "Price       59      Billy  86-(878)547-7739   Asia/Shanghai"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple conditions can be set to narrow down or widen the filter\n",
    "only_billy_and_peter = df.loc[(df[\"first_name\"] == \"Billy\") | (\n",
    "    df[\"first_name\"] == \"Peter\"), :]\n",
    "\n",
    "only_billy_and_peter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Students Turn - 04 - Good Movies - üë©‚Äçüéìüë®‚Äçüéì\n",
    "## Good Movies\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Use Pandas to load and display the CSV provided in `Resources`.\n",
    "\n",
    "* List all the columns in the data set.\n",
    "\n",
    "* We're only interested in IMDb data, so create a new table that takes the Film and all the columns relating to IMDB.\n",
    "\n",
    "* Filter out only the good movies‚Äîi.e., any film with an IMDb score greater than or equal to 7 and remove the norm ratings.\n",
    "\n",
    "* Find less popular movies that you may not have heard about - i.e., anything with under 20K votes\n",
    "\n",
    "Data Source:[Moving Rating Dataset](https://github.com/fivethirtyeight/data/blob/master/fandango/fandango_score_comparison.csv)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencie\n",
    "import pandas as pd\n",
    "\n",
    "# Load in file\n",
    "movie_file = \"Resources/movie_scores.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILM</th>\n",
       "      <th>RottenTomatoes</th>\n",
       "      <th>RottenTomatoes_User</th>\n",
       "      <th>Metacritic</th>\n",
       "      <th>Metacritic_User</th>\n",
       "      <th>IMDB</th>\n",
       "      <th>Fandango_Stars</th>\n",
       "      <th>Fandango_Ratingvalue</th>\n",
       "      <th>RT_norm</th>\n",
       "      <th>RT_user_norm</th>\n",
       "      <th>...</th>\n",
       "      <th>IMDB_norm</th>\n",
       "      <th>RT_norm_round</th>\n",
       "      <th>RT_user_norm_round</th>\n",
       "      <th>Metacritic_norm_round</th>\n",
       "      <th>Metacritic_user_norm_round</th>\n",
       "      <th>IMDB_norm_round</th>\n",
       "      <th>Metacritic_user_vote_count</th>\n",
       "      <th>IMDB_user_vote_count</th>\n",
       "      <th>Fandango_votes</th>\n",
       "      <th>Fandango_Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avengers: Age of Ultron (2015)</td>\n",
       "      <td>74</td>\n",
       "      <td>86</td>\n",
       "      <td>66</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.70</td>\n",
       "      <td>4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1330</td>\n",
       "      <td>271107</td>\n",
       "      <td>14846</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cinderella (2015)</td>\n",
       "      <td>85</td>\n",
       "      <td>80</td>\n",
       "      <td>67</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.55</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>249</td>\n",
       "      <td>65709</td>\n",
       "      <td>12640</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ant-Man (2015)</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>64</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>627</td>\n",
       "      <td>103660</td>\n",
       "      <td>12055</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do You Believe? (2015)</td>\n",
       "      <td>18</td>\n",
       "      <td>84</td>\n",
       "      <td>22</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>31</td>\n",
       "      <td>3136</td>\n",
       "      <td>1793</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hot Tub Time Machine 2 (2015)</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>88</td>\n",
       "      <td>19560</td>\n",
       "      <td>1021</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             FILM  RottenTomatoes  RottenTomatoes_User  \\\n",
       "0  Avengers: Age of Ultron (2015)              74                   86   \n",
       "1               Cinderella (2015)              85                   80   \n",
       "2                  Ant-Man (2015)              80                   90   \n",
       "3          Do You Believe? (2015)              18                   84   \n",
       "4   Hot Tub Time Machine 2 (2015)              14                   28   \n",
       "\n",
       "   Metacritic  Metacritic_User  IMDB  Fandango_Stars  Fandango_Ratingvalue  \\\n",
       "0          66              7.1   7.8             5.0                   4.5   \n",
       "1          67              7.5   7.1             5.0                   4.5   \n",
       "2          64              8.1   7.8             5.0                   4.5   \n",
       "3          22              4.7   5.4             5.0                   4.5   \n",
       "4          29              3.4   5.1             3.5                   3.0   \n",
       "\n",
       "   RT_norm  RT_user_norm  ...  IMDB_norm  RT_norm_round  RT_user_norm_round  \\\n",
       "0     3.70           4.3  ...       3.90            3.5                 4.5   \n",
       "1     4.25           4.0  ...       3.55            4.5                 4.0   \n",
       "2     4.00           4.5  ...       3.90            4.0                 4.5   \n",
       "3     0.90           4.2  ...       2.70            1.0                 4.0   \n",
       "4     0.70           1.4  ...       2.55            0.5                 1.5   \n",
       "\n",
       "   Metacritic_norm_round  Metacritic_user_norm_round  IMDB_norm_round  \\\n",
       "0                    3.5                         3.5              4.0   \n",
       "1                    3.5                         4.0              3.5   \n",
       "2                    3.0                         4.0              4.0   \n",
       "3                    1.0                         2.5              2.5   \n",
       "4                    1.5                         1.5              2.5   \n",
       "\n",
       "   Metacritic_user_vote_count  IMDB_user_vote_count  Fandango_votes  \\\n",
       "0                        1330                271107           14846   \n",
       "1                         249                 65709           12640   \n",
       "2                         627                103660           12055   \n",
       "3                          31                  3136            1793   \n",
       "4                          88                 19560            1021   \n",
       "\n",
       "   Fandango_Difference  \n",
       "0                  0.5  \n",
       "1                  0.5  \n",
       "2                  0.5  \n",
       "3                  0.5  \n",
       "4                  0.5  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read and display the CSV with Pandas\n",
    "movie_file_df = pd.read_csv(movie_file)\n",
    "movie_file_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FILM', 'RottenTomatoes', 'RottenTomatoes_User', 'Metacritic',\n",
       "       'Metacritic_User', 'IMDB', 'Fandango_Stars', 'Fandango_Ratingvalue',\n",
       "       'RT_norm', 'RT_user_norm', 'Metacritic_norm', 'Metacritic_user_nom',\n",
       "       'IMDB_norm', 'RT_norm_round', 'RT_user_norm_round',\n",
       "       'Metacritic_norm_round', 'Metacritic_user_norm_round',\n",
       "       'IMDB_norm_round', 'Metacritic_user_vote_count', 'IMDB_user_vote_count',\n",
       "       'Fandango_votes', 'Fandango_Difference'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all the columns in the table\n",
    "movie_file_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILM</th>\n",
       "      <th>IMDB</th>\n",
       "      <th>IMDB_norm</th>\n",
       "      <th>IMDB_norm_round</th>\n",
       "      <th>IMDB_user_vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avengers: Age of Ultron (2015)</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>271107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cinderella (2015)</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.5</td>\n",
       "      <td>65709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ant-Man (2015)</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do You Believe? (2015)</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hot Tub Time Machine 2 (2015)</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.5</td>\n",
       "      <td>19560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             FILM  IMDB  IMDB_norm  IMDB_norm_round  \\\n",
       "0  Avengers: Age of Ultron (2015)   7.8       3.90              4.0   \n",
       "1               Cinderella (2015)   7.1       3.55              3.5   \n",
       "2                  Ant-Man (2015)   7.8       3.90              4.0   \n",
       "3          Do You Believe? (2015)   5.4       2.70              2.5   \n",
       "4   Hot Tub Time Machine 2 (2015)   5.1       2.55              2.5   \n",
       "\n",
       "   IMDB_user_vote_count  \n",
       "0                271107  \n",
       "1                 65709  \n",
       "2                103660  \n",
       "3                  3136  \n",
       "4                 19560  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We only want IMDb data, so create a new table that takes the Film and all the columns relating to IMDB\n",
    "imdb_df = movie_file_df[[\"FILM\", \"IMDB\", \"IMDB_norm\",\n",
    "                            \"IMDB_norm_round\", \"IMDB_user_vote_count\"]]\n",
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILM</th>\n",
       "      <th>IMDB</th>\n",
       "      <th>IMDB_user_vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avengers: Age of Ultron (2015)</td>\n",
       "      <td>7.8</td>\n",
       "      <td>271107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cinderella (2015)</td>\n",
       "      <td>7.1</td>\n",
       "      <td>65709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ant-Man (2015)</td>\n",
       "      <td>7.8</td>\n",
       "      <td>103660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Water Diviner (2015)</td>\n",
       "      <td>7.2</td>\n",
       "      <td>39373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shaun the Sheep Movie (2015)</td>\n",
       "      <td>7.4</td>\n",
       "      <td>12227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             FILM  IMDB  IMDB_user_vote_count\n",
       "0  Avengers: Age of Ultron (2015)   7.8                271107\n",
       "1               Cinderella (2015)   7.1                 65709\n",
       "2                  Ant-Man (2015)   7.8                103660\n",
       "5        The Water Diviner (2015)   7.2                 39373\n",
       "8    Shaun the Sheep Movie (2015)   7.4                 12227"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We only like good movies, so find those that scored over 7, and ignore the norm rating\n",
    "good_movies_df = movie_file_df.loc[movie_file_df[\"IMDB\"] > 7, [\n",
    "    \"FILM\", \"IMDB\", \"IMDB_user_vote_count\"]]\n",
    "good_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILM</th>\n",
       "      <th>IMDB</th>\n",
       "      <th>IMDB_user_vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shaun the Sheep Movie (2015)</td>\n",
       "      <td>7.4</td>\n",
       "      <td>12227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Love &amp; Mercy (2015)</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Far From The Madding Crowd (2015)</td>\n",
       "      <td>7.2</td>\n",
       "      <td>12129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>McFarland, USA (2015)</td>\n",
       "      <td>7.5</td>\n",
       "      <td>13769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The End of the Tour (2015)</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 FILM  IMDB  IMDB_user_vote_count\n",
       "8        Shaun the Sheep Movie (2015)   7.4                 12227\n",
       "9                 Love & Mercy (2015)   7.8                  5367\n",
       "10  Far From The Madding Crowd (2015)   7.2                 12129\n",
       "20              McFarland, USA (2015)   7.5                 13769\n",
       "29         The End of the Tour (2015)   7.9                  1320"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find less popular movies--i.e., those with fewer than 20K votes\n",
    "unknown_movies_df = good_movies_df.loc[good_movies_df[\"IMDB_user_vote_count\"] < 20000, [\n",
    "    \"FILM\", \"IMDB\", \"IMDB_user_vote_count\"]]\n",
    "unknown_movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><strong>Activity 04 Solution ‚úÖ</strong></summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "# Dependencie\n",
    "import pandas as pd\n",
    "\n",
    "# Load in file\n",
    "movie_file = \"Resources/movie_scores.csv\"\n",
    "\n",
    "# Read and display the CSV with Pandas\n",
    "movie_file_df = pd.read_csv(movie_file)\n",
    "movie_file_df.head()\n",
    "\n",
    "# List all the columns in the table\n",
    "movie_file_df.columns\n",
    "\n",
    "\n",
    "# We only want IMDb data, so create a new table that takes the Film and all the columns relating to IMDB\n",
    "imdb_df = movie_file_df[[\"FILM\", \"IMDB\", \"IMDB_norm\",\n",
    "                            \"IMDB_norm_round\", \"IMDB_user_vote_count\"]]\n",
    "imdb_df.head()\n",
    "\n",
    "# We only like good movies, so find those that scored over 7, and ignore the norm rating\n",
    "good_movies_df = movie_file_df.loc[movie_file_df[\"IMDB\"] > 7, [\n",
    "    \"FILM\", \"IMDB\", \"IMDB_user_vote_count\"]]\n",
    "good_movies_df.head()\n",
    "\n",
    "# Find less popular movies--i.e., those with fewer than 20K votes\n",
    "unknown_movies_df = good_movies_df.loc[good_movies_df[\"IMDB_user_vote_count\"] < 20000, [\n",
    "    \"FILM\", \"IMDB\", \"IMDB_user_vote_count\"]]\n",
    "unknown_movies_df.head()\n",
    "\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor Turn - 05 - GroupBy - üë©‚Äçüè´üßë‚Äçüè´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/10/1949 20:30</td>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700</td>\n",
       "      <td>45 minutes</td>\n",
       "      <td>This event took place in early fall around 194...</td>\n",
       "      <td>4/27/2004</td>\n",
       "      <td>29.8830556</td>\n",
       "      <td>-97.941111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/10/1949 21:00</td>\n",
       "      <td>lackland afb</td>\n",
       "      <td>tx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>light</td>\n",
       "      <td>7200</td>\n",
       "      <td>1-2 hrs</td>\n",
       "      <td>1949 Lackland AFB&amp;#44 TX.  Lights racing acros...</td>\n",
       "      <td>12/16/2005</td>\n",
       "      <td>29.38421</td>\n",
       "      <td>-98.581082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/10/1955 17:00</td>\n",
       "      <td>chester (uk/england)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>20 seconds</td>\n",
       "      <td>Green/Orange circular disc over Chester&amp;#44 En...</td>\n",
       "      <td>1/21/2008</td>\n",
       "      <td>53.2</td>\n",
       "      <td>-2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/10/1956 21:00</td>\n",
       "      <td>edna</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>1/2 hour</td>\n",
       "      <td>My older brother and twin sister were leaving ...</td>\n",
       "      <td>1/17/2004</td>\n",
       "      <td>28.9783333</td>\n",
       "      <td>-96.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/10/1960 20:00</td>\n",
       "      <td>kaneohe</td>\n",
       "      <td>hi</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>900</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>AS a Marine 1st Lt. flying an FJ4B fighter/att...</td>\n",
       "      <td>1/22/2004</td>\n",
       "      <td>21.4180556</td>\n",
       "      <td>-157.803611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           datetime                  city state country     shape  \\\n",
       "0  10/10/1949 20:30            san marcos    tx      us  cylinder   \n",
       "1  10/10/1949 21:00          lackland afb    tx     NaN     light   \n",
       "2  10/10/1955 17:00  chester (uk/england)   NaN      gb    circle   \n",
       "3  10/10/1956 21:00                  edna    tx      us    circle   \n",
       "4  10/10/1960 20:00               kaneohe    hi      us     light   \n",
       "\n",
       "  duration (seconds) duration (hours/min)  \\\n",
       "0               2700           45 minutes   \n",
       "1               7200              1-2 hrs   \n",
       "2                 20           20 seconds   \n",
       "3                 20             1/2 hour   \n",
       "4                900           15 minutes   \n",
       "\n",
       "                                            comments date posted    latitude  \\\n",
       "0  This event took place in early fall around 194...   4/27/2004  29.8830556   \n",
       "1  1949 Lackland AFB&#44 TX.  Lights racing acros...  12/16/2005    29.38421   \n",
       "2  Green/Orange circular disc over Chester&#44 En...   1/21/2008        53.2   \n",
       "3  My older brother and twin sister were leaving ...   1/17/2004  28.9783333   \n",
       "4  AS a Marine 1st Lt. flying an FJ4B fighter/att...   1/22/2004  21.4180556   \n",
       "\n",
       "   longitude   \n",
       "0  -97.941111  \n",
       "1  -98.581082  \n",
       "2   -2.916667  \n",
       "3  -96.645833  \n",
       "4 -157.803611  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# Create a reference the CSV file desired\n",
    "csv_path = \"Resources/ufoSightings.csv\"\n",
    "\n",
    "# Read the CSV into a Pandas DataFrame\n",
    "ufo_df = pd.read_csv(csv_path, low_memory = False)\n",
    "\n",
    "# Print the first five rows of data to the screen\n",
    "ufo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                66516\n",
       "city                    66516\n",
       "state                   66516\n",
       "country                 66516\n",
       "shape                   66516\n",
       "duration (seconds)      66516\n",
       "duration (hours/min)    66516\n",
       "comments                66516\n",
       "date posted             66516\n",
       "latitude                66516\n",
       "longitude               66516\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the rows with missing data\n",
    "clean_ufo_df = ufo_df.dropna(how=\"any\")\n",
    "clean_ufo_df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                 object\n",
       "city                     object\n",
       "state                    object\n",
       "country                  object\n",
       "shape                    object\n",
       "duration (seconds)       object\n",
       "duration (hours/min)     object\n",
       "comments                 object\n",
       "date posted              object\n",
       "latitude                 object\n",
       "longitude               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ufo_df.head()\n",
    "clean_ufo_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                 object\n",
       "city                     object\n",
       "state                    object\n",
       "country                  object\n",
       "shape                    object\n",
       "duration (seconds)      float64\n",
       "duration (hours/min)     object\n",
       "comments                 object\n",
       "date posted              object\n",
       "latitude                 object\n",
       "longitude               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the \"duration (seconds)\" column's values to numeric\n",
    "converted_ufo = clean_ufo_df.copy()\n",
    "converted_ufo[\"duration (seconds)\"] = converted_ufo.loc[:, \"duration (seconds)\"].astype(float)\n",
    "\n",
    "converted_ufo.head()\n",
    "converted_ufo.dtypes #to check that conversion was correctly executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/10/1949 20:30</td>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>45 minutes</td>\n",
       "      <td>This event took place in early fall around 194...</td>\n",
       "      <td>4/27/2004</td>\n",
       "      <td>29.8830556</td>\n",
       "      <td>-97.941111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/10/1956 21:00</td>\n",
       "      <td>edna</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1/2 hour</td>\n",
       "      <td>My older brother and twin sister were leaving ...</td>\n",
       "      <td>1/17/2004</td>\n",
       "      <td>28.9783333</td>\n",
       "      <td>-96.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/10/1960 20:00</td>\n",
       "      <td>kaneohe</td>\n",
       "      <td>hi</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>900.0</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>AS a Marine 1st Lt. flying an FJ4B fighter/att...</td>\n",
       "      <td>1/22/2004</td>\n",
       "      <td>21.4180556</td>\n",
       "      <td>-157.803611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10/10/1961 19:00</td>\n",
       "      <td>bristol</td>\n",
       "      <td>tn</td>\n",
       "      <td>us</td>\n",
       "      <td>sphere</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>My father is now 89 my brother 52 the girl wit...</td>\n",
       "      <td>4/27/2007</td>\n",
       "      <td>36.595</td>\n",
       "      <td>-82.188889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10/10/1965 23:45</td>\n",
       "      <td>norwalk</td>\n",
       "      <td>ct</td>\n",
       "      <td>us</td>\n",
       "      <td>disk</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>20 minutes</td>\n",
       "      <td>A bright orange color changing to reddish colo...</td>\n",
       "      <td>10/2/1999</td>\n",
       "      <td>41.1175</td>\n",
       "      <td>-73.408333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           datetime        city state country     shape  duration (seconds)  \\\n",
       "0  10/10/1949 20:30  san marcos    tx      us  cylinder              2700.0   \n",
       "3  10/10/1956 21:00        edna    tx      us    circle                20.0   \n",
       "4  10/10/1960 20:00     kaneohe    hi      us     light               900.0   \n",
       "5  10/10/1961 19:00     bristol    tn      us    sphere               300.0   \n",
       "7  10/10/1965 23:45     norwalk    ct      us      disk              1200.0   \n",
       "\n",
       "  duration (hours/min)                                           comments  \\\n",
       "0           45 minutes  This event took place in early fall around 194...   \n",
       "3             1/2 hour  My older brother and twin sister were leaving ...   \n",
       "4           15 minutes  AS a Marine 1st Lt. flying an FJ4B fighter/att...   \n",
       "5            5 minutes  My father is now 89 my brother 52 the girl wit...   \n",
       "7           20 minutes  A bright orange color changing to reddish colo...   \n",
       "\n",
       "  date posted    latitude  longitude   \n",
       "0   4/27/2004  29.8830556  -97.941111  \n",
       "3   1/17/2004  28.9783333  -96.645833  \n",
       "4   1/22/2004  21.4180556 -157.803611  \n",
       "5   4/27/2007      36.595  -82.188889  \n",
       "7   10/2/1999     41.1175  -73.408333  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the data so that only those sightings in the US are in a DataFrame\n",
    "usa_ufo_df = converted_ufo.loc[converted_ufo[\"country\"] == \"us\", :]\n",
    "usa_ufo_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ca    8683\n",
       "fl    3754\n",
       "wa    3707\n",
       "tx    3398\n",
       "ny    2915\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many sightings have occured within each state\n",
    "state_counts = usa_ufo_df[\"state\"].value_counts()\n",
    "state_counts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fe924ef1fd0>\n"
     ]
    }
   ],
   "source": [
    "# Using GroupBy in order to separate the data into fields according to \"state\" values\n",
    "grouped_usa_df = usa_ufo_df.groupby(['state'])\n",
    "\n",
    "# The object returned is a \"GroupBy\" object and cannot be viewed normally...\n",
    "print(grouped_usa_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "ak     1455863.00\n",
       "al      900453.50\n",
       "ar    66986144.50\n",
       "az    15453494.60\n",
       "ca    24865571.47\n",
       "co     1923709.00\n",
       "ct     3110318.80\n",
       "dc        1645.50\n",
       "de      142969.50\n",
       "fl    55900005.00\n",
       "ga     9519878.10\n",
       "hi     6732485.00\n",
       "ia      613576.00\n",
       "id      475270.30\n",
       "il     2133923.07\n",
       "in     4032395.70\n",
       "ks      830518.50\n",
       "ky     3435497.50\n",
       "la     6819072.00\n",
       "ma     1602861.00\n",
       "md      688074.30\n",
       "me      654476.90\n",
       "mi     1895119.10\n",
       "mn     1382802.33\n",
       "mo     1614738.80\n",
       "ms     3396695.00\n",
       "mt     1050599.00\n",
       "nc     2056718.35\n",
       "nd      140274.00\n",
       "ne      412354.00\n",
       "nh     1072798.50\n",
       "nj     7784974.00\n",
       "nm     4055283.59\n",
       "nv     2393413.95\n",
       "ny     8898149.55\n",
       "oh     3284932.80\n",
       "ok      853112.30\n",
       "or     1774625.28\n",
       "pa     9110355.00\n",
       "pr       26200.00\n",
       "ri      472900.50\n",
       "sc     1089566.80\n",
       "sd      480358.50\n",
       "tn     1854526.30\n",
       "tx     8444239.25\n",
       "ut     3417964.00\n",
       "va    13606781.00\n",
       "vt      264785.50\n",
       "wa    56618769.44\n",
       "wi     2323749.30\n",
       "wv     2974853.00\n",
       "wy      251443.00\n",
       "Name: duration (seconds), dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to be visualized, a data function must be used...\n",
    "grouped_usa_df.count().head(10)\n",
    "\n",
    "grouped_usa_df[\"duration (seconds)\"].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "ak     1455863.00\n",
       "al      900453.50\n",
       "ar    66986144.50\n",
       "az    15453494.60\n",
       "ca    24865571.47\n",
       "Name: duration (seconds), dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since \"duration (seconds)\" was converted to a numeric time, it can now be summed up per state\n",
    "state_duration = grouped_usa_df[\"duration (seconds)\"].sum()\n",
    "state_duration.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Sightings</th>\n",
       "      <th>Total Visit Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ak</th>\n",
       "      <td>311</td>\n",
       "      <td>1455863.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>al</th>\n",
       "      <td>629</td>\n",
       "      <td>900453.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ar</th>\n",
       "      <td>578</td>\n",
       "      <td>66986144.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>az</th>\n",
       "      <td>2362</td>\n",
       "      <td>15453494.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>8683</td>\n",
       "      <td>24865571.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of Sightings  Total Visit Time\n",
       "ak                  311        1455863.00\n",
       "al                  629         900453.50\n",
       "ar                  578       66986144.50\n",
       "az                 2362       15453494.60\n",
       "ca                 8683       24865571.47"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new DataFrame using both duration and count\n",
    "state_summary_table = pd.DataFrame({\"Number of Sightings\": state_counts,\n",
    "                                    \"Total Visit Time\": state_duration})\n",
    "state_summary_table.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">au</th>\n",
       "      <th>al</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dc</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nt</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oh</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sa</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wa</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yt</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">ca</th>\n",
       "      <th>ab</th>\n",
       "      <td>284</td>\n",
       "      <td>284</td>\n",
       "      <td>284</td>\n",
       "      <td>284</td>\n",
       "      <td>284</td>\n",
       "      <td>284</td>\n",
       "      <td>284</td>\n",
       "      <td>284</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc</th>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mb</th>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nf</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ns</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nt</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>1335</td>\n",
       "      <td>1335</td>\n",
       "      <td>1335</td>\n",
       "      <td>1335</td>\n",
       "      <td>1335</td>\n",
       "      <td>1335</td>\n",
       "      <td>1335</td>\n",
       "      <td>1335</td>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pe</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pq</th>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qc</th>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sa</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sk</th>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime  city  shape  duration (seconds)  \\\n",
       "country state                                              \n",
       "au      al            1     1      1                   1   \n",
       "        dc            1     1      1                   1   \n",
       "        nt            2     2      2                   2   \n",
       "        oh            1     1      1                   1   \n",
       "        sa            2     2      2                   2   \n",
       "        wa            2     2      2                   2   \n",
       "        yt            1     1      1                   1   \n",
       "ca      ab          284   284    284                 284   \n",
       "        bc          677   677    677                 677   \n",
       "        mb          124   124    124                 124   \n",
       "        nb           86    86     86                  86   \n",
       "        nf           15    15     15                  15   \n",
       "        ns          101   101    101                 101   \n",
       "        nt           13    13     13                  13   \n",
       "        on         1335  1335   1335                1335   \n",
       "        pe           10    10     10                  10   \n",
       "        pq           62    62     62                  62   \n",
       "        qc          124   124    124                 124   \n",
       "        sa           27    27     27                  27   \n",
       "        sk           77    77     77                  77   \n",
       "\n",
       "               duration (hours/min)  comments  date posted  latitude  \\\n",
       "country state                                                          \n",
       "au      al                        1         1            1         1   \n",
       "        dc                        1         1            1         1   \n",
       "        nt                        2         2            2         2   \n",
       "        oh                        1         1            1         1   \n",
       "        sa                        2         2            2         2   \n",
       "        wa                        2         2            2         2   \n",
       "        yt                        1         1            1         1   \n",
       "ca      ab                      284       284          284       284   \n",
       "        bc                      677       677          677       677   \n",
       "        mb                      124       124          124       124   \n",
       "        nb                       86        86           86        86   \n",
       "        nf                       15        15           15        15   \n",
       "        ns                      101       101          101       101   \n",
       "        nt                       13        13           13        13   \n",
       "        on                     1335      1335         1335      1335   \n",
       "        pe                       10        10           10        10   \n",
       "        pq                       62        62           62        62   \n",
       "        qc                      124       124          124       124   \n",
       "        sa                       27        27           27        27   \n",
       "        sk                       77        77           77        77   \n",
       "\n",
       "               longitude   \n",
       "country state              \n",
       "au      al              1  \n",
       "        dc              1  \n",
       "        nt              2  \n",
       "        oh              1  \n",
       "        sa              2  \n",
       "        wa              2  \n",
       "        yt              1  \n",
       "ca      ab            284  \n",
       "        bc            677  \n",
       "        mb            124  \n",
       "        nb             86  \n",
       "        nf             15  \n",
       "        ns            101  \n",
       "        nt             13  \n",
       "        on           1335  \n",
       "        pe             10  \n",
       "        pq             62  \n",
       "        qc            124  \n",
       "        sa             27  \n",
       "        sk             77  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is also possible to group a DataFrame by multiple columns\n",
    "# This returns an object with multiple indexes, however, which can be harder to deal with\n",
    "grouped_international_data = converted_ufo.groupby(['country', 'state'])\n",
    "\n",
    "grouped_international_data.count().head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>duration (seconds)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">au</th>\n",
       "      <th>al</th>\n",
       "      <td>900.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dc</th>\n",
       "      <td>300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nt</th>\n",
       "      <td>360.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oh</th>\n",
       "      <td>180.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sa</th>\n",
       "      <td>305.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wa</th>\n",
       "      <td>450.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yt</th>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ca</th>\n",
       "      <th>ab</th>\n",
       "      <td>530994.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc</th>\n",
       "      <td>641955.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mb</th>\n",
       "      <td>160132.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               duration (seconds)\n",
       "country state                    \n",
       "au      al                 900.00\n",
       "        dc                 300.00\n",
       "        nt                 360.00\n",
       "        oh                 180.00\n",
       "        sa                 305.00\n",
       "        wa                 450.00\n",
       "        yt                  30.00\n",
       "ca      ab              530994.00\n",
       "        bc              641955.82\n",
       "        mb              160132.00"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Converting a GroupBy object into a DataFrame\n",
    "international_duration = pd.DataFrame(\n",
    "    grouped_international_data[\"duration (seconds)\"].sum())\n",
    "international_duration.head(10)\n",
    "\n",
    "#international_duration.to_csv(\"\", header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Turn - 06 - Training Grounds - üë©‚Äçüéìüë®‚Äçüéì\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Using the DataFrame provided, do the following:\n",
    "\n",
    "    * Convert the \"Membership (Days)\" column into weeks and then add this new series into the DataFrame\n",
    "\n",
    "    * Create a Dataframe that has only the \"Trainer\", \"Weight\", and membership in days and weeks.\n",
    "\n",
    "    * Using groupby get the average weight and length membership of the gym members for each trainer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Trainer</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Membership (Days)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gino Walker</td>\n",
       "      <td>Bettyann Savory</td>\n",
       "      <td>128</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiedi Wasser</td>\n",
       "      <td>Mariah Barberio</td>\n",
       "      <td>180</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerrie Wetzel</td>\n",
       "      <td>Gordon Perrine</td>\n",
       "      <td>193</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elizabeth Sackett</td>\n",
       "      <td>Pa Dargan</td>\n",
       "      <td>177</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jack Mitten</td>\n",
       "      <td>Blanch Victoria</td>\n",
       "      <td>237</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name          Trainer  Weight  Membership (Days)\n",
       "0        Gino Walker  Bettyann Savory     128                 52\n",
       "1       Hiedi Wasser  Mariah Barberio     180                 70\n",
       "2      Kerrie Wetzel   Gordon Perrine     193                148\n",
       "3  Elizabeth Sackett        Pa Dargan     177                124\n",
       "4        Jack Mitten  Blanch Victoria     237                186"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A seriously gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members\n",
    "training_data = pd.DataFrame({\n",
    "    \"Name\":[\"Gino Walker\",\"Hiedi Wasser\",\"Kerrie Wetzel\",\"Elizabeth Sackett\",\"Jack Mitten\",\"Madalene Wayman\",\"Jamee Horvath\",\"Arlena Reddin\",\"Tula Levan\",\"Teisha Dreier\",\"Leslie Carrier\",\"Arlette Hartson\",\"Romana Merkle\",\"Heath Viviani\",\"Andres Zimmer\",\"Allyson Osman\",\"Yadira Caggiano\",\"Jeanmarie Friedrichs\",\"Leann Ussery\",\"Bee Mom\",\"Pandora Charland\",\"Karena Wooten\",\"Elizabet Albanese\",\"Augusta Borjas\",\"Erma Yadon\",\"Belia Lenser\",\"Karmen Sancho\",\"Edison Mannion\",\"Sonja Hornsby\",\"Morgan Frei\",\"Florencio Murphy\",\"Christoper Hertel\",\"Thalia Stepney\",\"Tarah Argento\",\"Nicol Canfield\",\"Pok Moretti\",\"Barbera Stallings\",\"Muoi Kelso\",\"Cicely Ritz\",\"Sid Demelo\",\"Eura Langan\",\"Vanita An\",\"Frieda Fuhr\",\"Ernest Fitzhenry\",\"Ashlyn Tash\",\"Melodi Mclendon\",\"Rochell Leblanc\",\"Jacqui Reasons\",\"Freeda Mccroy\",\"Vanna Runk\",\"Florinda Milot\",\"Cierra Lecompte\",\"Nancey Kysar\",\"Latasha Dalton\",\"Charlyn Rinaldi\",\"Erline Averett\",\"Mariko Hillary\",\"Rosalyn Trigg\",\"Sherwood Brauer\",\"Hortencia Olesen\",\"Delana Kohut\",\"Geoffrey Mcdade\",\"Iona Delancey\",\"Donnie Read\",\"Cesar Bhatia\",\"Evia Slate\",\"Kaye Hugo\",\"Denise Vento\",\"Lang Kittle\",\"Sherry Whittenberg\",\"Jodi Bracero\",\"Tamera Linneman\",\"Katheryn Koelling\",\"Tonia Shorty\",\"Misha Baxley\",\"Lisbeth Goering\",\"Merle Ladwig\",\"Tammie Omar\",\"Jesusa Avilla\",\"Alda Zabala\",\"Junita Dogan\",\"Jessia Anglin\",\"Peggie Scranton\",\"Dania Clodfelter\",\"Janis Mccarthy\",\"Edmund Galusha\",\"Tonisha Posey\",\"Arvilla Medley\",\"Briana Barbour\",\"Delfina Kiger\",\"Nia Lenig\",\"Ricarda Bulow\",\"Odell Carson\",\"Nydia Clonts\",\"Andree Resendez\",\"Daniela Puma\",\"Sherill Paavola\",\"Gilbert Bloomquist\",\"Shanon Mach\",\"Justin Bangert\",\"Arden Hokanson\",\"Evelyne Bridge\",\"Hee Simek\",\"Ward Deangelis\",\"Jodie Childs\",\"Janis Boehme\",\"Beaulah Glowacki\",\"Denver Stoneham\",\"Tarra Vinton\",\"Deborah Hummell\",\"Ulysses Neil\",\"Kathryn Marques\",\"Rosanna Dake\",\"Gavin Wheat\",\"Tameka Stoke\",\"Janella Clear\",\"Kaye Ciriaco\",\"Suk Bloxham\",\"Gracia Whaley\",\"Philomena Hemingway\",\"Claudette Vaillancourt\",\"Olevia Piche\",\"Trey Chiles\",\"Idalia Scardina\",\"Jenine Tremble\",\"Herbert Krider\",\"Alycia Schrock\",\"Miss Weibel\",\"Pearlene Neidert\",\"Kina Callender\",\"Charlotte Skelley\",\"Theodora Harrigan\",\"Sydney Shreffler\",\"Annamae Trinidad\",\"Tobi Mumme\",\"Rosia Elliot\",\"Debbra Putt\",\"Rena Delosantos\",\"Genna Grennan\",\"Nieves Huf\",\"Berry Lugo\",\"Ayana Verdugo\",\"Joaquin Mazzei\",\"Doris Harmon\",\"Patience Poss\",\"Magaret Zabel\",\"Marylynn Hinojos\",\"Earlene Marcantel\",\"Yuki Evensen\",\"Rema Gay\",\"Delana Haak\",\"Patricia Fetters\",\"Vinnie Elrod\",\"Octavia Bellew\",\"Burma Revard\",\"Lakenya Kato\",\"Vinita Buchner\",\"Sierra Margulies\",\"Shae Funderburg\",\"Jenae Groleau\",\"Louetta Howie\",\"Astrid Duffer\",\"Caron Altizer\",\"Kymberly Amavisca\",\"Mohammad Diedrich\",\"Thora Wrinkle\",\"Bethel Wiemann\",\"Patria Millet\",\"Eldridge Burbach\",\"Alyson Eddie\",\"Zula Hanna\",\"Devin Goodwin\",\"Felipa Kirkwood\",\"Kurtis Kempf\",\"Kasey Lenart\",\"Deena Blankenship\",\"Kandra Wargo\",\"Sherrie Cieslak\",\"Ron Atha\",\"Reggie Barreiro\",\"Daria Saulter\",\"Tandra Eastman\",\"Donnell Lucious\",\"Talisha Rosner\",\"Emiko Bergh\",\"Terresa Launius\",\"Margy Hoobler\",\"Marylou Stelling\",\"Lavonne Justice\",\"Kala Langstaff\",\"China Truett\",\"Louanne Dussault\",\"Thomasena Samaniego\",\"Charlesetta Tarbell\",\"Fatimah Lade\",\"Malisa Cantero\",\"Florencia Litten\",\"Francina Fraise\",\"Patsy London\",\"Deloris Mclaughlin\"],\n",
    "    \"Trainer\":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],\n",
    "    \"Weight\":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],\n",
    "    \"Membership (Days)\":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]\n",
    "})\n",
    "training_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the membership days into weeks and then add a this data in a new column to the DataFrame.\n",
    "\n",
    "# Create a Dataframe that has the Trainer, Weight, and Membership.\n",
    "\n",
    "# Using groupby get the average weight and length membership for each trainer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><strong>Activity 06 Solution ‚úÖ</strong></summary>\n",
    "    \n",
    "```python\n",
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# A seriously gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members\n",
    "training_data = pd.DataFrame({\n",
    "    \"Name\":[\"Gino Walker\",\"Hiedi Wasser\",\"Kerrie Wetzel\",\"Elizabeth Sackett\",\"Jack Mitten\",\"Madalene Wayman\",\"Jamee Horvath\",\"Arlena Reddin\",\"Tula Levan\",\"Teisha Dreier\",\"Leslie Carrier\",\"Arlette Hartson\",\"Romana Merkle\",\"Heath Viviani\",\"Andres Zimmer\",\"Allyson Osman\",\"Yadira Caggiano\",\"Jeanmarie Friedrichs\",\"Leann Ussery\",\"Bee Mom\",\"Pandora Charland\",\"Karena Wooten\",\"Elizabet Albanese\",\"Augusta Borjas\",\"Erma Yadon\",\"Belia Lenser\",\"Karmen Sancho\",\"Edison Mannion\",\"Sonja Hornsby\",\"Morgan Frei\",\"Florencio Murphy\",\"Christoper Hertel\",\"Thalia Stepney\",\"Tarah Argento\",\"Nicol Canfield\",\"Pok Moretti\",\"Barbera Stallings\",\"Muoi Kelso\",\"Cicely Ritz\",\"Sid Demelo\",\"Eura Langan\",\"Vanita An\",\"Frieda Fuhr\",\"Ernest Fitzhenry\",\"Ashlyn Tash\",\"Melodi Mclendon\",\"Rochell Leblanc\",\"Jacqui Reasons\",\"Freeda Mccroy\",\"Vanna Runk\",\"Florinda Milot\",\"Cierra Lecompte\",\"Nancey Kysar\",\"Latasha Dalton\",\"Charlyn Rinaldi\",\"Erline Averett\",\"Mariko Hillary\",\"Rosalyn Trigg\",\"Sherwood Brauer\",\"Hortencia Olesen\",\"Delana Kohut\",\"Geoffrey Mcdade\",\"Iona Delancey\",\"Donnie Read\",\"Cesar Bhatia\",\"Evia Slate\",\"Kaye Hugo\",\"Denise Vento\",\"Lang Kittle\",\"Sherry Whittenberg\",\"Jodi Bracero\",\"Tamera Linneman\",\"Katheryn Koelling\",\"Tonia Shorty\",\"Misha Baxley\",\"Lisbeth Goering\",\"Merle Ladwig\",\"Tammie Omar\",\"Jesusa Avilla\",\"Alda Zabala\",\"Junita Dogan\",\"Jessia Anglin\",\"Peggie Scranton\",\"Dania Clodfelter\",\"Janis Mccarthy\",\"Edmund Galusha\",\"Tonisha Posey\",\"Arvilla Medley\",\"Briana Barbour\",\"Delfina Kiger\",\"Nia Lenig\",\"Ricarda Bulow\",\"Odell Carson\",\"Nydia Clonts\",\"Andree Resendez\",\"Daniela Puma\",\"Sherill Paavola\",\"Gilbert Bloomquist\",\"Shanon Mach\",\"Justin Bangert\",\"Arden Hokanson\",\"Evelyne Bridge\",\"Hee Simek\",\"Ward Deangelis\",\"Jodie Childs\",\"Janis Boehme\",\"Beaulah Glowacki\",\"Denver Stoneham\",\"Tarra Vinton\",\"Deborah Hummell\",\"Ulysses Neil\",\"Kathryn Marques\",\"Rosanna Dake\",\"Gavin Wheat\",\"Tameka Stoke\",\"Janella Clear\",\"Kaye Ciriaco\",\"Suk Bloxham\",\"Gracia Whaley\",\"Philomena Hemingway\",\"Claudette Vaillancourt\",\"Olevia Piche\",\"Trey Chiles\",\"Idalia Scardina\",\"Jenine Tremble\",\"Herbert Krider\",\"Alycia Schrock\",\"Miss Weibel\",\"Pearlene Neidert\",\"Kina Callender\",\"Charlotte Skelley\",\"Theodora Harrigan\",\"Sydney Shreffler\",\"Annamae Trinidad\",\"Tobi Mumme\",\"Rosia Elliot\",\"Debbra Putt\",\"Rena Delosantos\",\"Genna Grennan\",\"Nieves Huf\",\"Berry Lugo\",\"Ayana Verdugo\",\"Joaquin Mazzei\",\"Doris Harmon\",\"Patience Poss\",\"Magaret Zabel\",\"Marylynn Hinojos\",\"Earlene Marcantel\",\"Yuki Evensen\",\"Rema Gay\",\"Delana Haak\",\"Patricia Fetters\",\"Vinnie Elrod\",\"Octavia Bellew\",\"Burma Revard\",\"Lakenya Kato\",\"Vinita Buchner\",\"Sierra Margulies\",\"Shae Funderburg\",\"Jenae Groleau\",\"Louetta Howie\",\"Astrid Duffer\",\"Caron Altizer\",\"Kymberly Amavisca\",\"Mohammad Diedrich\",\"Thora Wrinkle\",\"Bethel Wiemann\",\"Patria Millet\",\"Eldridge Burbach\",\"Alyson Eddie\",\"Zula Hanna\",\"Devin Goodwin\",\"Felipa Kirkwood\",\"Kurtis Kempf\",\"Kasey Lenart\",\"Deena Blankenship\",\"Kandra Wargo\",\"Sherrie Cieslak\",\"Ron Atha\",\"Reggie Barreiro\",\"Daria Saulter\",\"Tandra Eastman\",\"Donnell Lucious\",\"Talisha Rosner\",\"Emiko Bergh\",\"Terresa Launius\",\"Margy Hoobler\",\"Marylou Stelling\",\"Lavonne Justice\",\"Kala Langstaff\",\"China Truett\",\"Louanne Dussault\",\"Thomasena Samaniego\",\"Charlesetta Tarbell\",\"Fatimah Lade\",\"Malisa Cantero\",\"Florencia Litten\",\"Francina Fraise\",\"Patsy London\",\"Deloris Mclaughlin\"],\n",
    "    \"Trainer\":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],\n",
    "    \"Weight\":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],\n",
    "    \"Membership (Days)\":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]\n",
    "})\n",
    "training_data.head()\n",
    "\n",
    "# Convert the membership days into weeks and then add a this data in a new column to the DataFrame.\n",
    "weeks = training_data[\"Membership (Days)\"]/7\n",
    "training_data[\"Membership (Weeks)\"] = weeks\n",
    "\n",
    "training_data.head()\n",
    "\n",
    "# Create a Dataframe that has the Trainer, Weight, and Membership.\n",
    "trainers_data =  training_data[[\"Trainer\", \"Weight\", \"Membership (Days)\", \"Membership (Weeks)\"]]\n",
    "trainers_data\n",
    "\n",
    "# Using groupby get the average weight and length membership for each trainer.\n",
    "\n",
    "trainers_means = trainers_data.groupby([\"Trainer\"]).mean()\n",
    "trainers_means\n",
    "\n",
    "trainers_means.sort_values(by='Membership (Days)', ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor Turn - 07 - Binning - üë©‚Äçüè´üßë‚Äçüè´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Name</th>\n",
       "      <th>Final Exam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Rami</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Erika</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Shawn</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Nijah</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Robert</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spring</td>\n",
       "      <td>John</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Safira</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Spring</td>\n",
       "      <td>An</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Steven</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Tomas</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class    Name  Final Exam\n",
       "0  Spring    Rami          56\n",
       "1  Spring   Erika          71\n",
       "2  Spring   Shawn          85\n",
       "3  Spring   Nijah          67\n",
       "4  Spring  Robert          68\n",
       "5  Spring    John          73\n",
       "6  Spring  Safira          84\n",
       "7  Spring      An          90\n",
       "8  Spring  Steven          73\n",
       "9  Spring   Tomas          84"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# Load in file\n",
    "final_exam_scores = \"resources/final_exam_scores.csv\"\n",
    "\n",
    "df = pd.read_csv(final_exam_scores)\n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Name</th>\n",
       "      <th>Final Exam</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Rami</td>\n",
       "      <td>56</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Erika</td>\n",
       "      <td>71</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Shawn</td>\n",
       "      <td>85</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Nijah</td>\n",
       "      <td>67</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Robert</td>\n",
       "      <td>68</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spring</td>\n",
       "      <td>John</td>\n",
       "      <td>73</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Safira</td>\n",
       "      <td>84</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Spring</td>\n",
       "      <td>An</td>\n",
       "      <td>90</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Steven</td>\n",
       "      <td>73</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Tomas</td>\n",
       "      <td>84</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class    Name  Final Exam Grade\n",
       "0  Spring    Rami          56     F\n",
       "1  Spring   Erika          71     C\n",
       "2  Spring   Shawn          85     B\n",
       "3  Spring   Nijah          67     D\n",
       "4  Spring  Robert          68     D\n",
       "5  Spring    John          73     C\n",
       "6  Spring  Safira          84     B\n",
       "7  Spring      An          90     A\n",
       "8  Spring  Steven          73     C\n",
       "9  Spring   Tomas          84     B"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create the bins in which Data will be held\n",
    "# Bins are 0, 59, 69, 79, 89, 100.   \n",
    "bins = [0, 59, 69, 79, 89, 100]\n",
    "\n",
    "# Create the names for the four bins\n",
    "group_names = [\"F\", \"D\", \"C\", \"B\", \"A\"]\n",
    "\n",
    "df[\"Grade\"] = pd.cut(df[\"Final Exam\"], bins, labels=group_names)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Final Exam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grade</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>6.0</td>\n",
       "      <td>57.166667</td>\n",
       "      <td>1.329160</td>\n",
       "      <td>56.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>6.0</td>\n",
       "      <td>65.833333</td>\n",
       "      <td>3.060501</td>\n",
       "      <td>61.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>6.0</td>\n",
       "      <td>73.166667</td>\n",
       "      <td>3.125167</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.5</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>7.0</td>\n",
       "      <td>84.142857</td>\n",
       "      <td>2.410295</td>\n",
       "      <td>80.0</td>\n",
       "      <td>83.5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>5.0</td>\n",
       "      <td>95.600000</td>\n",
       "      <td>3.130495</td>\n",
       "      <td>90.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Final Exam                                                   \n",
       "           count       mean       std   min   25%   50%   75%   max\n",
       "Grade                                                              \n",
       "F            6.0  57.166667  1.329160  56.0  56.0  57.0  58.0  59.0\n",
       "D            6.0  65.833333  3.060501  61.0  64.0  67.5  68.0  68.0\n",
       "C            6.0  73.166667  3.125167  70.0  71.5  73.0  73.0  79.0\n",
       "B            7.0  84.142857  2.410295  80.0  83.5  84.0  85.0  88.0\n",
       "A            5.0  95.600000  3.130495  90.0  97.0  97.0  97.0  97.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the summary statitics of each letter grade. \n",
    "df = df.groupby(\"Grade\")\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Turn - 08 - Binning Ted - üë©‚Äçüéìüë®‚Äçüéì\n",
    "## Binning TED\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Read in the CSV file provided and print it to the screen.\n",
    "\n",
    "* Find the minimum \"views\" and maximum \"views\".\n",
    "\n",
    "* Using the minimum and maximum \"views\" as a reference, create 10 bins in which to slice the data.\n",
    "\n",
    "* Create a new column called \"View Group\" and fill it with the values collected through your slicing.\n",
    "\n",
    "* Group the DataFrame based upon the values within \"View Group\".\n",
    "\n",
    "* Find out how many rows fall into each group before finding the averages for \"comments\", \"duration\", and \"languages\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>languages</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4553</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>1164</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>60</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>Ken Robinson: Do schools kill creativity?</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>47227110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>265</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>977</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>43</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Al Gore: Averting the climate crisis</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>3200520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>New York Times columnist David Pogue takes aim...</td>\n",
       "      <td>1286</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>26</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>David Pogue: Simplicity sells</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>1636292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>In an emotionally charged talk, MacArthur-winn...</td>\n",
       "      <td>1116</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>35</td>\n",
       "      <td>Majora Carter</td>\n",
       "      <td>Majora Carter: Greening the ghetto</td>\n",
       "      <td>Greening the ghetto</td>\n",
       "      <td>1697550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>You've never seen data presented like this. Wi...</td>\n",
       "      <td>1190</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>48</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>Hans Rosling: The best stats you've ever seen</td>\n",
       "      <td>The best stats you've ever seen</td>\n",
       "      <td>12005869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comments                                        description  duration  \\\n",
       "0      4553  Sir Ken Robinson makes an entertaining and pro...      1164   \n",
       "1       265  With the same humor and humanity he exuded in ...       977   \n",
       "2       124  New York Times columnist David Pogue takes aim...      1286   \n",
       "3       200  In an emotionally charged talk, MacArthur-winn...      1116   \n",
       "4       593  You've never seen data presented like this. Wi...      1190   \n",
       "\n",
       "     event  languages   main_speaker  \\\n",
       "0  TED2006         60   Ken Robinson   \n",
       "1  TED2006         43        Al Gore   \n",
       "2  TED2006         26    David Pogue   \n",
       "3  TED2006         35  Majora Carter   \n",
       "4  TED2006         48   Hans Rosling   \n",
       "\n",
       "                                            name  \\\n",
       "0      Ken Robinson: Do schools kill creativity?   \n",
       "1           Al Gore: Averting the climate crisis   \n",
       "2                  David Pogue: Simplicity sells   \n",
       "3             Majora Carter: Greening the ghetto   \n",
       "4  Hans Rosling: The best stats you've ever seen   \n",
       "\n",
       "                             title     views  \n",
       "0      Do schools kill creativity?  47227110  \n",
       "1      Averting the climate crisis   3200520  \n",
       "2                 Simplicity sells   1636292  \n",
       "3              Greening the ghetto   1697550  \n",
       "4  The best stats you've ever seen  12005869  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# Create a path to the csv and read it into a Pandas DataFrame\n",
    "csv_path = \"Resources/ted_talks.csv\"\n",
    "ted_df = pd.read_csv(csv_path)\n",
    "\n",
    "ted_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out the minimum and maximum views for a TED Talk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins in which to place values based upon TED Talk views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels for these bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the data and place it into bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the data series into a new column inside of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GroupBy object based upon \"View Group\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how many rows fall into each bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average of each column within the GroupBy object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><strong>Activity 08 Solution ‚úÖ</strong></summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# Create a path to the csv and read it into a Pandas DataFrame\n",
    "csv_path = \"Resources/ted_talks.csv\"\n",
    "ted_df = pd.read_csv(csv_path)\n",
    "\n",
    "ted_df.head()\n",
    "\n",
    "# Figure out the minimum and maximum views for a TED Talk\n",
    "print(ted_df[\"views\"].max())\n",
    "print(ted_df[\"views\"].min())\n",
    "\n",
    "# Create bins in which to place values based upon TED Talk views\n",
    "bins = [0, 199999, 399999, 599999, 799999, 999999,\n",
    "        1999999, 2999999, 3999999, 4999999, 50000000]\n",
    "\n",
    "# Create labels for these bins\n",
    "group_labels = [\"0 to 199k\", \"200k to 399k\", \"400k to 599k\", \"600k to 799k\", \"800k to 999k\", \"1mil to 2mil\",\n",
    "                \"2mil to 3mil\", \"3mil to 4mil\", \"4mil to 5mil\", \"5mil to 50mil\"]\n",
    "\n",
    "# Slice the data and place it into bins\n",
    "pd.cut(ted_df[\"views\"], bins, labels=group_labels).head()\n",
    "\n",
    "# Place the data series into a new column inside of the DataFrame\n",
    "ted_df[\"View Group\"] = pd.cut(ted_df[\"views\"], bins, labels=group_labels)\n",
    "ted_df.head()\n",
    "\n",
    "# Create a GroupBy object based upon \"View Group\"\n",
    "ted_group = ted_df.groupby(\"View Group\")\n",
    "\n",
    "# Find how many rows fall into each bin\n",
    "print(ted_group[\"comments\"].count())\n",
    "\n",
    "# Get the average of each column within the GroupBy object\n",
    "ted_group[[\"comments\", \"duration\", \"languages\"]].mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
